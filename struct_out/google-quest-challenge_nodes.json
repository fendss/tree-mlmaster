[
    [
        {
            "demo_id": "google-quest-challenge",
            "node_index": 2,
            "metric": null,
            "plan": "To tackle this multi-label regression task, we'll use a DistilBERT model fine-\ntuned on the provided text data. The model will process concatenated question\nand answer text to predict 30 continuous targets. We'll split the training data\nto create a validation set, compute the mean Spearman correlation as the\nevaluation metric, and generate test predictions for submission.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertTokenizer, DistilBertModel, AdamW\nimport torch.nn as nn\n\n# Data preparation\ntrain = pd.read_csv(\"input/train.csv\")\ntest = pd.read_csv(\"input/test.csv\")\n\n\ndef combine_text(row):\n    return f\"{row['question_title']} [SEP] {row['question_body']} [SEP] {row['answer']}\"\n\n\ntrain[\"text\"] = train.apply(combine_text, axis=1)\ntest[\"text\"] = test.apply(combine_text, axis=1)\n\ntarget_cols = [col for col in train.columns if col.startswith((\"question_\", \"answer_\"))]\nX_train, X_val, y_train, y_val = train_test_split(\n    train[\"text\"], train[target_cols], test_size=0.2, random_state=42\n)\n\n# Dataset setup\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nmax_len = 512\n\n\nclass QADataset(Dataset):\n    def __init__(self, texts, labels=None):\n        self.texts = texts.reset_index(drop=True)\n        self.labels = labels.values if labels is not None else None\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        inputs = tokenizer(\n            text,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=max_len,\n            return_tensors=\"pt\",\n        )\n        item = {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.FloatTensor(self.labels[idx])\n        return item\n\n\ntrain_dataset = QADataset(X_train, y_train)\nval_dataset = QADataset(X_val, y_val)\ntest_dataset = QADataset(test[\"text\"])\n\n\n# Model architecture\nclass RegressionBERT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n        self.dropout = nn.Dropout(0.1)\n        self.regressor = nn.Linear(self.bert.config.hidden_size, 30)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = outputs.last_hidden_state[:, 0]\n        pooled = self.dropout(pooled)\n        return torch.sigmoid(self.regressor(pooled))\n\n\n# Training configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = RegressionBERT().to(device)\noptimizer = AdamW(model.parameters(), lr=2e-5)\ncriterion = nn.MSELoss()\nbatch_size = 32\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\n# Training loop\nfor epoch in range(3):\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n        labels = batch[\"labels\"].to(device)\n        outputs = model(**inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n# Validation\nmodel.eval()\nval_preds, val_labels = [], []\nwith torch.no_grad():\n    for batch in val_loader:\n        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n        labels = batch[\"labels\"].cpu().numpy()\n        preds = model(**inputs).cpu().numpy()\n        val_preds.append(preds)\n        val_labels.append(labels)\n\nval_preds = np.concatenate(val_preds)\nval_labels = np.concatenate(val_labels)\nspearman_scores = [spearmanr(val_preds[:, i], val_labels[:, i])[0] for i in range(30)]\nmean_score = np.nanmean(spearman_scores)\nprint(f\"Validation Mean Spearman: {mean_score:.4f}\")\n\n# Generate submission\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs = {k: v.to(device) for k, v in batch.items()}\n        preds = model(**inputs).cpu().numpy()\n        test_preds.append(preds)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=target_cols)\nsubmission.insert(0, \"qa_id\", test[\"qa_id\"].values)\nsubmission.to_csv(\"submission/submission.csv\", index=False)\n",
            "analysis": "The code execution failed due to a TypeError in the DataLoader worker process. Specifically, the error occurred when trying to convert a numpy object array to a torch FloatTensor, which is not supported. As a result, the validation metric could not be calculated and the submission file was not successfully generated.",
            "is_bug": "True",
            "parent_index": 0,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 数值标准化(StandardScaler) 对10个numerical列\n类别编码: one-hot→index (Wilderness_Area1-4、Soil_Type1-40)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化, DataLoader batch=4096, shuffle=True, num_workers=4\n模型构建: Embedding + ResNet-MLP，输入10+4+16→512，blocks: 512→512、512→512、512→256、256→256，输出256→7，包含SE注意力模块\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、weight_decay=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, wd=0.01；OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n训练循环: 前向→损失→反向→更新→调度, epochs=25",
            "insights_from_parent": [
                "父节点为根节点，无需分析"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 4,
            "metric": 0.3185,
            "plan": "The error occurs because the label columns are stored as object dtype instead of\nfloat. To fix this, we need to explicitly convert target columns to float32\nafter loading the data. Additionally, we ensure proper column ordering by\naligning with the sample submission's format.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertTokenizer, DistilBertModel, AdamW\nimport torch.nn as nn\n\n# Load data and ensure correct column order\nsample_sub = pd.read_csv(\"input/sample_submission.csv\")\ntarget_cols = sample_sub.columns[1:].tolist()\n\ntrain = pd.read_csv(\"input/train.csv\")\ntest = pd.read_csv(\"input/test.csv\")\n\n# Convert target columns to float32\ntrain[target_cols] = train[target_cols].astype(np.float32)\n\n\n# Text preprocessing\ndef combine_text(row):\n    return f\"{row['question_title']} [SEP] {row['question_body']} [SEP] {row['answer']}\"\n\n\ntrain[\"text\"] = train.apply(combine_text, axis=1)\ntest[\"text\"] = test.apply(combine_text, axis=1)\n\n# Split data with correct target order\nX_train, X_val, y_train, y_val = train_test_split(\n    train[\"text\"], train[target_cols], test_size=0.2, random_state=42\n)\n\n# Dataset class with proper dtype handling\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nmax_len = 512\n\n\nclass QADataset(Dataset):\n    def __init__(self, texts, labels=None):\n        self.texts = texts.reset_index(drop=True)\n        self.labels = labels.values.astype(np.float32) if labels is not None else None\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        inputs = tokenizer(\n            text,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=max_len,\n            return_tensors=\"pt\",\n        )\n        item = {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.FloatTensor(self.labels[idx])\n        return item\n\n\n# Create datasets and loaders\ntrain_dataset = QADataset(X_train, y_train)\nval_dataset = QADataset(X_val, y_val)\ntest_dataset = QADataset(test[\"text\"])\n\n\n# Model definition remains the same\nclass RegressionBERT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n        self.dropout = nn.Dropout(0.1)\n        self.regressor = nn.Linear(self.bert.config.hidden_size, 30)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = outputs.last_hidden_state[:, 0]\n        return torch.sigmoid(self.regressor(self.dropout(pooled)))\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = RegressionBERT().to(device)\noptimizer = AdamW(model.parameters(), lr=2e-5)\ncriterion = nn.MSELoss()\n\n# Training loop with increased num_workers\nbatch_size = 32\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\n# Training\nfor epoch in range(3):\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n        labels = batch[\"labels\"].to(device)\n        outputs = model(**inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n# Validation\nmodel.eval()\nval_preds, val_labels = [], []\nwith torch.no_grad():\n    for batch in val_loader:\n        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n        labels = batch[\"labels\"].cpu().numpy()\n        preds = model(**inputs).cpu().numpy()\n        val_preds.append(preds)\n        val_labels.append(labels)\n\nval_preds = np.concatenate(val_preds)\nval_labels = np.concatenate(val_labels)\nspearman_scores = [spearmanr(val_preds[:, i], val_labels[:, i])[0] for i in range(30)]\nmean_score = np.nanmean(spearman_scores)\nprint(f\"Validation Mean Spearman: {mean_score:.4f}\")\n\n# Generate submission with correct column order\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs = {k: v.to(device) for k, v in batch.items()}\n        preds = model(**inputs).cpu().numpy()\n        test_preds.append(preds)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=target_cols)\nsubmission.insert(0, \"qa_id\", test[\"qa_id\"].values)\nsubmission.to_csv(\"submission/submission.csv\", index=False)\n",
            "analysis": "The code successfully executed without any bugs and produced a submission file in the required directory. The validation mean Spearman correlation coefficient is 0.3185, indicating moderate predictive performance of the model on the validation set. The metric used, Spearman's correlation, should be maximized, as higher values indicate better ranking correlation between predictions and true values.",
            "is_bug": "False",
            "parent_index": 2,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 数值标准化(StandardScaler) 对10个数值特征\n类别编码: 从one-hot还原类别索引(idxmax→0-based)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化(TensorDataset)、DataLoader batch=4096、shuffle=True（train）、num_workers=4\n模型构建: Embedding + ResNet-MLP，输入10+4+16→512，残差块序列(512→512,512→512,512→256,256→256)，输出线性256→7，残差块含SE注意力\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, wd=0.01；OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n训练循环: 前向→损失→反向→更新→调度",
            "insights_from_parent": [
                "数据预处理：显式将目标列转换为float32并依据sample_submission对齐列顺序，修复object dtype和列错位问题，保证标签数值正确传入模型和评估。",
                "特征工程：与父节点保持一致，文本拼接与分词未改，未引入额外特征或预处理步骤。",
                "模型选择：模型结构不变，仍使用DistilBERT微调，回归头与dropout配置沿用父节点。",
                "参数调整：主要超参（lr=2e-5、batch_size=32、dropout=0.1）未调整，DataLoader num_workers 保持4，未引入学习率调度或正则新策略。",
                "训练策略：训练循环、损失函数（MSELoss）和评估（按列Spearman）未变化；但通过修正标签dtype与列顺序提升了训练稳定性与评估/提交的正确性。"
            ]
        }
    ],
    [
        {
            "demo_id": "google-quest-challenge",
            "node_index": 7,
            "metric": null,
            "plan": "To address the multi-target regression task, we'll use a RoBERTa model to\nseparately encode question and answer texts. Each text's CLS embedding is\nextracted, concatenated, and passed through an MLP to predict all 30 targets. A\n20% validation split is used to compute the mean Spearman correlation. The model\nis trained with MSE loss and AdamW optimizer, ensuring predictions are clipped\nto [0,1]. This approach captures distinct semantic features from questions and\nanswers separately.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, AdamW\nfrom scipy.stats import spearmanr\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass QAModel(nn.Module):\n    def __init__(self, model_name=\"roberta-base\", num_labels=30):\n        super().__init__()\n        self.roberta = AutoModel.from_pretrained(model_name)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.roberta.config.hidden_size * 2, 512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, num_labels),\n        )\n\n    def forward(self, q_ids, q_mask, a_ids, a_mask):\n        q_emb = self.roberta(q_ids, q_mask).last_hidden_state[:, 0]\n        a_emb = self.roberta(a_ids, a_mask).last_hidden_state[:, 0]\n        return self.regressor(torch.cat([q_emb, a_emb], 1))\n\n\nclass QADataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=192):\n        self.texts = df.apply(\n            lambda x: (f\"{x['question_title']} {x['question_body']}\", str(x[\"answer\"])),\n            axis=1,\n        )\n        self.targets = df.iloc[:, 11:41].values\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        q, a = self.texts.iloc[idx]\n        q_tok = self.tokenizer(\n            q,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        a_tok = self.tokenizer(\n            a,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        return {\n            k: v.squeeze(0) for d in [q_tok, a_tok] for k, v in d.items()\n        }, torch.FloatTensor(self.targets[idx])\n\n\n# Data preparation\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n\n# Model setup\nmodel = QAModel().to(device)\noptim = AdamW(model.parameters(), lr=1.5e-5)\nloss_fn = nn.MSELoss()\n\n\n# DataLoaders\ndef collate_fn(batch):\n    q = {\n        k: torch.stack([x[0][k] for x in batch])\n        for k in [\"input_ids\", \"attention_mask\"]\n    }\n    a = {\n        k: torch.stack([x[0][f\"{k}_1\"] for x in batch])\n        for k in [\"input_ids\", \"attention_mask\"]\n    }\n    t = torch.stack([x[1] for x in batch])\n    return (q[\"input_ids\"], q[\"attention_mask\"], a[\"input_ids\"], a[\"attention_mask\"]), t\n\n\ntrain_loader = DataLoader(\n    QADataset(train, tokenizer),\n    batch_size=32,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=4,\n)\nval_loader = DataLoader(QADataset(val, tokenizer), batch_size=64, collate_fn=collate_fn)\n\n# Training loop\nbest_score = 0\nfor epoch in range(4):\n    model.train()\n    for inputs, targets in train_loader:\n        inputs = [x.to(device) for x in inputs]\n        targets = targets.to(device)\n        optim.zero_grad()\n        preds = model(*inputs)\n        loss = loss_fn(preds, targets)\n        loss.backward()\n        optim.step()\n\n    # Validation\n    model.eval()\n    preds, truths = [], []\n    with torch.no_grad():\n        for inputs, t in val_loader:\n            inputs = [x.to(device) for x in inputs]\n            preds.append(model(*inputs).cpu())\n            truths.append(t)\n    preds = torch.cat(preds).numpy()\n    truths = torch.cat(truths).numpy()\n    score = np.nanmean(\n        [spearmanr(preds[:, i], truths[:, i]).correlation for i in range(30)]\n    )\n    print(f\"Epoch {epoch+1} Val Score: {score:.4f}\")\n    if score > best_score:\n        best_score = score\n        torch.save(model.state_dict(), \"./working/best.pt\")\n\n# Generate predictions\nmodel.load_state_dict(torch.load(\"./working/best.pt\"))\ntest_df = pd.read_csv(\"./input/test.csv\")\ntest_ds = QADataset(test_df, tokenizer)\ntest_loader = DataLoader(test_ds, batch_size=64, collate_fn=lambda b: collate_fn(b)[0])\n\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for inputs in test_loader:\n        inputs = [x.to(device) for x in inputs]\n        preds.append(model(*inputs).cpu())\npreds = torch.cat(preds).numpy().clip(0, 1)\n\nsub = pd.read_csv(\"./input/sample_submission.csv\")\nsub.iloc[:, 1:] = preds\nos.makedirs(\"./submission\", exist_ok=True)\nsub.to_csv(\"./submission/submission.csv\", index=False)\n\nprint(f\"Final Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code execution failed due to a KeyError related to the DataLoader worker process. Specifically, the error occurred because the key 'input_ids_1' was not found in the batch during the collation process. As a result, the validation metric could not be computed and the submission.csv file was not properly produced.",
            "is_bug": "True",
            "parent_index": 0,
            "node_level_analysis": "数据划分: hold-out 80/20，train_test_split test_size=0.2, random_state=42\n特征工程: 数值标准化 StandardScaler 应用于指定数值列\n类别编码: one-hot → 索引 (idxmax 提取 Wilderness_Area1-4、Soil_Type1-40 的类别索引并 -1)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化(TensorDataset)、DataLoader batch=4096、shuffle=True(训练)、num_workers=4\n模型构建: EmbeddingResNet；输入 Linear(10+4+16→512) + BatchNorm1d + GELU，残差块序列(512→512, 512→512, 512→256, 256→256) 含 SE 模块，输出 Linear(256→7)\n正则化: BatchNorm1d、Dropout(p=0.3/0.3/0.2/0.2)、weight decay=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, wd=0.01；OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n训练: epoch=25，训练循环 前向→损失→反向→更新→调度；基于验证准确率保存最佳模型\n预测与后处理: logits.argmax→类别，提交时 +1 恢复到 1-7",
            "insights_from_parent": [
                "根节点，无需分析"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 10,
            "metric": 0.3448,
            "plan": "The error occurs because the DataLoader collate function tries to access invalid\nkeys (`input_ids_1`) that weren't generated by the dataset. We need to properly\nseparate question/answer tokenization keys and adjust the collate function\naccordingly. The model structure and training loop are otherwise correct.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, AdamW\nfrom scipy.stats import spearmanr\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass QAModel(nn.Module):\n    def __init__(self, model_name=\"roberta-base\", num_labels=30):\n        super().__init__()\n        self.roberta = AutoModel.from_pretrained(model_name)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.roberta.config.hidden_size * 2, 512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, num_labels),\n        )\n\n    def forward(self, q_ids, q_mask, a_ids, a_mask):\n        q_emb = self.roberta(q_ids, q_mask).last_hidden_state[:, 0]\n        a_emb = self.roberta(a_ids, a_mask).last_hidden_state[:, 0]\n        return self.regressor(torch.cat([q_emb, a_emb], 1))\n\n\nclass QADataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=192):\n        self.texts = df.apply(\n            lambda x: (f\"{x['question_title']} {x['question_body']}\", str(x[\"answer\"])),\n            axis=1,\n        )\n        self.targets = (\n            df.iloc[:, 11:41].values\n            if \"question_asker_intent_understanding\" in df.columns\n            else None\n        )\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        q, a = self.texts.iloc[idx]\n        q_tok = self.tokenizer(\n            q,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        a_tok = self.tokenizer(\n            a,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        item = {\n            \"q_input_ids\": q_tok[\"input_ids\"].squeeze(0),\n            \"q_attention_mask\": q_tok[\"attention_mask\"].squeeze(0),\n            \"a_input_ids\": a_tok[\"input_ids\"].squeeze(0),\n            \"a_attention_mask\": a_tok[\"attention_mask\"].squeeze(0),\n        }\n        if self.targets is not None:\n            return item, torch.FloatTensor(self.targets[idx])\n        return item\n\n\ndef collate_fn(batch):\n    is_train = isinstance(batch[0], tuple)\n    if is_train:\n        inputs = [x[0] for x in batch]\n        targets = torch.stack([x[1] for x in batch])\n    else:\n        inputs = batch\n\n    q_ids = torch.stack([x[\"q_input_ids\"] for x in inputs])\n    q_mask = torch.stack([x[\"q_attention_mask\"] for x in inputs])\n    a_ids = torch.stack([x[\"a_input_ids\"] for x in inputs])\n    a_mask = torch.stack([x[\"a_attention_mask\"] for x in inputs])\n\n    return (\n        (q_ids, q_mask, a_ids, a_mask, targets)\n        if is_train\n        else (q_ids, q_mask, a_ids, a_mask)\n    )\n\n\n# Prepare data and model\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n\nmodel = QAModel().to(device)\noptim = AdamW(model.parameters(), lr=1.5e-5)\nloss_fn = nn.MSELoss()\n\n# Data loaders with fixed collate\ntrain_loader = DataLoader(\n    QADataset(train, tokenizer),\n    batch_size=32,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=4,\n)\nval_loader = DataLoader(\n    QADataset(val, tokenizer), batch_size=64, collate_fn=collate_fn, num_workers=4\n)\n\n# Training loop\nbest_score = 0\nfor epoch in range(4):\n    model.train()\n    for q_ids, q_mask, a_ids, a_mask, targets in train_loader:\n        q_ids, q_mask = q_ids.to(device), q_mask.to(device)\n        a_ids, a_mask = a_ids.to(device), a_mask.to(device)\n        targets = targets.to(device)\n\n        optim.zero_grad()\n        preds = model(q_ids, q_mask, a_ids, a_mask)\n        loss = loss_fn(preds, targets)\n        loss.backward()\n        optim.step()\n\n    # Validation\n    model.eval()\n    val_preds, val_targets = [], []\n    with torch.no_grad():\n        for q_ids, q_mask, a_ids, a_mask, targets in val_loader:\n            q_ids, q_mask = q_ids.to(device), q_mask.to(device)\n            a_ids, a_mask = a_ids.to(device), a_mask.to(device)\n            preds = model(q_ids, q_mask, a_ids, a_mask)\n            val_preds.append(preds.cpu())\n            val_targets.append(targets.cpu())\n\n    val_preds = torch.cat(val_preds).numpy()\n    val_targets = torch.cat(val_targets).numpy()\n    scores = [\n        spearmanr(val_preds[:, i], val_targets[:, i]).correlation for i in range(30)\n    ]\n    score = np.nanmean(scores)\n    print(f\"Epoch {epoch+1} Val Score: {score:.4f}\")\n    if score > best_score:\n        best_score = score\n        torch.save(model.state_dict(), \"./working/best.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"./working/best.pt\"))\ntest_df = pd.read_csv(\"./input/test.csv\")\ntest_loader = DataLoader(\n    QADataset(test_df, tokenizer), batch_size=64, collate_fn=collate_fn\n)\n\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for q_ids, q_mask, a_ids, a_mask in test_loader:\n        q_ids, q_mask = q_ids.to(device), q_mask.to(device)\n        a_ids, a_mask = a_ids.to(device), a_mask.to(device)\n        batch_preds = model(q_ids, q_mask, a_ids, a_mask)\n        preds.append(batch_preds.cpu())\n\nsub = pd.DataFrame()\nsub[\"qa_id\"] = test_df[\"qa_id\"]\nsubmission_cols = pd.read_csv(\"./input/sample_submission.csv\").columns[1:]\nsub[submission_cols] = torch.cat(preds).numpy().clip(0, 1)\nos.makedirs(\"./submission\", exist_ok=True)\nsub.to_csv(\"./submission/submission.csv\", index=False)\n\nprint(f\"Final Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code successfully trains a model to predict subjective question-answering aspects using a dataset from StackExchange. The model achieves a final validation Spearman's correlation score of 0.3448, indicating a moderate level of agreement between the predicted and actual rankings. The predictions are saved in a 'submission.csv' file in the './submission/' directory, ready for evaluation. The code executes without any bugs or errors.",
            "is_bug": "False",
            "parent_index": 7,
            "node_level_analysis": "数据划分: train_test_split test_size=0.2, random_state=42（hold-out）\n\n特征工程: 数值特征标准化 StandardScaler（对10个数值列 fit/transform）\n\n类别编码: 将 one-hot 转索引 via idxmax() 并 -1（Wilderness_Area、Soil_Type → 整数类别）\n\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n\n数据管道: 张量化（torch.tensor dtype=float32/long），TensorDataset → DataLoader batch=4096, shuffle=True, num_workers=4\n\n模型构建: Embedding + ResNet-MLP；输入 10+4+16→512，blocks: 512→512 (×2, Dropout(p=0.3)), 512→256 (Dropout(p=0.2)), 256→256 (Dropout(p=0.2)), 输出 256→7；ResidualBlock + SE（Squeeze‑Excitation），Activation=GELU，BatchNorm1d 层\n\n正则化: Dropout(p=0.3/0.2)、BatchNorm1d、权重衰减 wd=0.01\n\n损失函数: CrossEntropyLoss\n\n优化与调度: AdamW lr=0.001, weight_decay=0.01；OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n\n训练循环: 前向→损失→反向→更新→调度 (epoch=25)",
            "insights_from_parent": [
                "数据预处理：规范化 token 字段名并支持 targets 可选出现",
                "特征工程：沿用 question/answer 分别编码并取 CLS 拼接（未变）",
                "模型选择：保留双编码 RoBERTa+MLP 回归架构",
                "参数调整：优化器/损失（AdamW + MSE）保持不变",
                "训练策略：修复 collate 函数与 batch 解包，提升数据加载稳定性"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 14,
            "metric": 0.3433,
            "plan": "The current solution uses separate RoBERTa embeddings for questions and answers.\nTo improve cross-modal interaction, we'll switch to a DeBERTa-v3 model\nprocessing concatenated question+answer sequences. This allows the model to\nattend across both texts simultaneously, capturing richer contextual\nrelationships. We'll also increase sequence length to 256 and use mean pooling\nof all token embeddings instead of just the [CLS] token to better preserve\ninformation.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    AutoTokenizer,\n    AutoModel,\n    AdamW,\n    get_linear_schedule_with_warmup,\n)\nfrom scipy.stats import spearmanr\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass QAModel(nn.Module):\n    def __init__(self, model_name=\"microsoft/deberta-v3-base\", num_labels=30):\n        super().__init__()\n        self.deberta = AutoModel.from_pretrained(model_name)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.deberta.config.hidden_size, 512),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, num_labels),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.deberta(input_ids, attention_mask)\n        hidden_state = outputs.last_hidden_state\n        pooled = hidden_state.mean(dim=1)\n        return self.regressor(pooled)\n\n\nclass QADataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=256):\n        self.texts = df.apply(\n            lambda x: f\"{x['question_title']} {x['question_body']} [SEP] {x['answer']}\",\n            axis=1,\n        ).values\n        self.targets = (\n            df.iloc[:, 11:41].values\n            if \"question_asker_intent_understanding\" in df.columns\n            else None\n        )\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        tokens = self.tokenizer(\n            text,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        item = {\n            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n        }\n        if self.targets is not None:\n            return item, torch.FloatTensor(self.targets[idx])\n        return item\n\n\ndef collate_fn(batch):\n    if isinstance(batch[0], tuple):\n        inputs = [x[0] for x in batch]\n        targets = torch.stack([x[1] for x in batch])\n        input_ids = torch.stack([x[\"input_ids\"] for x in inputs])\n        attention_mask = torch.stack([x[\"attention_mask\"] for x in inputs])\n        return input_ids, attention_mask, targets\n    else:\n        input_ids = torch.stack([x[\"input_ids\"] for x in batch])\n        attention_mask = torch.stack([x[\"attention_mask\"] for x in batch])\n        return input_ids, attention_mask\n\n\n# Prepare data and model\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\ntokenizer.sep_token = \"[SEP]\"\n\nmodel = QAModel().to(device)\noptim = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\nloss_fn = nn.BCELoss()\n\n# Data loaders\ntrain_loader = DataLoader(\n    QADataset(train, tokenizer),\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=4,\n)\nval_loader = DataLoader(\n    QADataset(val, tokenizer), batch_size=32, collate_fn=collate_fn, num_workers=4\n)\n\n# Training\nbest_score = 0\nepochs = 6\ntotal_steps = len(train_loader) * epochs\nscheduler = get_linear_schedule_with_warmup(\n    optim, num_warmup_steps=0.1 * total_steps, num_training_steps=total_steps\n)\n\nfor epoch in range(epochs):\n    model.train()\n    for input_ids, attn_mask, targets in train_loader:\n        input_ids = input_ids.to(device)\n        attn_mask = attn_mask.to(device)\n        targets = targets.to(device)\n\n        optim.zero_grad()\n        preds = model(input_ids, attn_mask)\n        loss = loss_fn(preds, targets)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optim.step()\n        scheduler.step()\n\n    # Validation\n    model.eval()\n    val_preds, val_targets = [], []\n    with torch.no_grad():\n        for input_ids, attn_mask, targets in val_loader:\n            input_ids = input_ids.to(device)\n            attn_mask = attn_mask.to(device)\n            batch_preds = model(input_ids, attn_mask)\n            val_preds.append(batch_preds.cpu())\n            val_targets.append(targets.cpu())\n\n    val_preds = torch.cat(val_preds).numpy()\n    val_targets = torch.cat(val_targets).numpy()\n    scores = [\n        spearmanr(val_preds[:, i], val_targets[:, i]).correlation for i in range(30)\n    ]\n    score = np.nanmean(scores)\n    print(f\"Epoch {epoch+1} Val Score: {score:.4f}\")\n    if score > best_score:\n        best_score = score\n        torch.save(model.state_dict(), \"./working/best.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"./working/best.pt\"))\ntest_df = pd.read_csv(\"./input/test.csv\")\ntest_loader = DataLoader(\n    QADataset(test_df, tokenizer), batch_size=32, collate_fn=collate_fn\n)\n\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for input_ids, attn_mask in test_loader:\n        input_ids = input_ids.to(device)\n        attn_mask = attn_mask.to(device)\n        batch_preds = model(input_ids, attn_mask)\n        preds.append(batch_preds.cpu())\n\nsub = pd.DataFrame()\nsub[\"qa_id\"] = test_df[\"qa_id\"]\nsubmission_cols = pd.read_csv(\"./input/sample_submission.csv\").columns[1:]\nsub[submission_cols] = torch.cat(preds).numpy()\nos.makedirs(\"./submission\", exist_ok=True)\nsub.to_csv(\"./submission/submission.csv\", index=False)\n\nprint(f\"Final Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code successfully executed and produced a submission file in the correct directory. The model was trained for 6 epochs, achieving a final validation Spearman's correlation of 0.3433. This metric should be maximized, indicating that the model's performance improved over the training epochs.",
            "is_bug": "False",
            "parent_index": 10,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 数值标准化(StandardScaler)对10个数值特征\n类别编码: one-hot→类别索引 via idxmax（Wilderness、Soil）\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化→DataLoader，batch=4096，shuffle=True(训练)，num_workers=4\n模型构建: Embedding + MLP(Linear 10+4+16→512) + 残差块(512→512,512→512,512→256,256→256)含SE与GELU，输出7类\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、权重衰减=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01)，OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n训练循环: 前向→损失→反向→更新→调度，epoch=25",
            "insights_from_parent": [
                "数据预处理：将 question+answer 合并为单序列，max_len 提升到 256，设置 sep_token",
                "特征工程：由 CLS 替换为对所有 token 的 mean pooling（更保留信息）",
                "模型选择：从双 RoBERTa 切换为单一 DeBERTa-v3 编码器",
                "参数调整：lr→2e-5、weight_decay→1e-4，输出加 Sigmoid，损失改为 BCELoss",
                "训练策略：引入线性 warmup 调度、梯度裁剪、减小 batch 并调整 epoch 次数"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 16,
            "metric": 0.3464,
            "plan": "To improve the model's feature extraction, we should correctly compute mean\npooling by excluding padding tokens using the attention mask. This ensures that\nonly valid input tokens contribute to the pooled representation, leading to\nbetter-quality embeddings for the regression task.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    AutoTokenizer,\n    AutoModel,\n    AdamW,\n    get_linear_schedule_with_warmup,\n)\nfrom scipy.stats import spearmanr\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass QAModel(nn.Module):\n    def __init__(self, model_name=\"microsoft/deberta-v3-base\", num_labels=30):\n        super().__init__()\n        self.deberta = AutoModel.from_pretrained(model_name)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.deberta.config.hidden_size, 512),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, num_labels),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.deberta(input_ids, attention_mask)\n        hidden_state = outputs.last_hidden_state\n\n        # Improved mean pooling using attention mask\n        input_mask_expanded = (\n            attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()\n        )\n        sum_embeddings = torch.sum(hidden_state * input_mask_expanded, dim=1)\n        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n        pooled = sum_embeddings / sum_mask\n\n        return self.regressor(pooled)\n\n\nclass QADataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=256):\n        self.texts = df.apply(\n            lambda x: f\"{x['question_title']} {x['question_body']} [SEP] {x['answer']}\",\n            axis=1,\n        ).values\n        self.targets = (\n            df.iloc[:, 11:41].values\n            if \"question_asker_intent_understanding\" in df.columns\n            else None\n        )\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        tokens = self.tokenizer(\n            text,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        item = {\n            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n        }\n        if self.targets is not None:\n            return item, torch.FloatTensor(self.targets[idx])\n        return item\n\n\ndef collate_fn(batch):\n    if isinstance(batch[0], tuple):\n        inputs = [x[0] for x in batch]\n        targets = torch.stack([x[1] for x in batch])\n        input_ids = torch.stack([x[\"input_ids\"] for x in inputs])\n        attention_mask = torch.stack([x[\"attention_mask\"] for x in inputs])\n        return input_ids, attention_mask, targets\n    else:\n        input_ids = torch.stack([x[\"input_ids\"] for x in batch])\n        attention_mask = torch.stack([x[\"attention_mask\"] for x in batch])\n        return input_ids, attention_mask\n\n\n# Prepare data and model\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\ntokenizer.sep_token = \"[SEP]\"\n\nmodel = QAModel().to(device)\noptim = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\nloss_fn = nn.BCELoss()\n\n# Data loaders\ntrain_loader = DataLoader(\n    QADataset(train, tokenizer),\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=4,\n)\nval_loader = DataLoader(\n    QADataset(val, tokenizer), batch_size=32, collate_fn=collate_fn, num_workers=4\n)\n\n# Training\nbest_score = 0\nepochs = 6\ntotal_steps = len(train_loader) * epochs\nscheduler = get_linear_schedule_with_warmup(\n    optim, num_warmup_steps=0.1 * total_steps, num_training_steps=total_steps\n)\n\nfor epoch in range(epochs):\n    model.train()\n    for input_ids, attn_mask, targets in train_loader:\n        input_ids = input_ids.to(device)\n        attn_mask = attn_mask.to(device)\n        targets = targets.to(device)\n\n        optim.zero_grad()\n        preds = model(input_ids, attn_mask)\n        loss = loss_fn(preds, targets)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optim.step()\n        scheduler.step()\n\n    # Validation\n    model.eval()\n    val_preds, val_targets = [], []\n    with torch.no_grad():\n        for input_ids, attn_mask, targets in val_loader:\n            input_ids = input_ids.to(device)\n            attn_mask = attn_mask.to(device)\n            batch_preds = model(input_ids, attn_mask)\n            val_preds.append(batch_preds.cpu())\n            val_targets.append(targets.cpu())\n\n    val_preds = torch.cat(val_preds).numpy()\n    val_targets = torch.cat(val_targets).numpy()\n    scores = [\n        spearmanr(val_preds[:, i], val_targets[:, i]).correlation for i in range(30)\n    ]\n    score = np.nanmean(scores)\n    print(f\"Epoch {epoch+1} Val Score: {score:.4f}\")\n    if score > best_score:\n        best_score = score\n        torch.save(model.state_dict(), \"./working/best.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"./working/best.pt\"))\ntest_df = pd.read_csv(\"./input/test.csv\")\ntest_loader = DataLoader(\n    QADataset(test_df, tokenizer), batch_size=32, collate_fn=collate_fn\n)\n\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for input_ids, attn_mask in test_loader:\n        input_ids = input_ids.to(device)\n        attn_mask = attn_mask.to(device)\n        batch_preds = model(input_ids, attn_mask)\n        preds.append(batch_preds.cpu())\n\nsub = pd.DataFrame()\nsub[\"qa_id\"] = test_df[\"qa_id\"]\nsubmission_cols = pd.read_csv(\"./input/sample_submission.csv\").columns[1:]\nsub[submission_cols] = torch.cat(preds).numpy()\nos.makedirs(\"./submission\", exist_ok=True)\nsub.to_csv(\"./submission/submission.csv\", index=False)\n\nprint(f\"Final Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The model was successfully trained and evaluated on the validation set with a final Spearman's correlation score of 0.3464. The metric used, Spearman's correlation, is a measure that should be maximized, indicating that higher values are better. The predictions were saved correctly to the submission.csv file in the designated submission directory.",
            "is_bug": "False",
            "parent_index": 14,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 数值特征(10列)标准化 StandardScaler(fit on train, transform on val/test)、one-hot转索引(Wilderness_Area1-4→0-3, Soil_Type1-40→0-39)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化(df→torch.tensor)、TensorDataset + DataLoader(batch=4096, shuffle=True(train), num_workers=4)，val batch=4096\n模型构建: Embedding + ResNet-like MLP，输入10+4+16→512，blocks: 512→512 x2、512→256、256→256，输出256→7\n正则化: BatchNorm1d、Dropout(p=0.3)/Dropout(p=0.2)、权重衰减=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, wd=0.01；OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n训练循环: epochs=25，前向→损失→反向→更新→调度",
            "insights_from_parent": [
                "数据预处理：保持合并 QA 且 max_len=256（未变）",
                "特征工程：改进 mean pooling，使用 attention_mask 排除 padding",
                "模型选择：沿用 DeBERTa 单编码器结构（不变）",
                "参数调整：超参与损失函数保持（lr/wd/BCELoss 不变）",
                "训练策略：保留调度与梯度裁剪，改进 pooling 提升表示质量"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 21,
            "metric": 0.3761,
            "plan": "To improve the model's ability to capture distinct features from questions and\nanswers, we'll process them through separate encoders. This allows each encoder\nto specialize in its respective text component, enhancing feature extraction.\nWe'll modify the architecture to include dual DeBERTa encoders for question and\nanswer processing, concatenate their pooled outputs, and adjust the training\npipeline to handle separated inputs.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    AutoTokenizer,\n    AutoModel,\n    AdamW,\n    get_linear_schedule_with_warmup,\n)\nfrom scipy.stats import spearmanr\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass QAModel(nn.Module):\n    def __init__(self, model_name=\"microsoft/deberta-v3-base\", num_labels=30):\n        super().__init__()\n        self.question_encoder = AutoModel.from_pretrained(model_name)\n        self.answer_encoder = AutoModel.from_pretrained(model_name)\n        self.regressor = nn.Sequential(\n            nn.Linear(2 * self.question_encoder.config.hidden_size, 512),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, num_labels),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, q_input_ids, q_attn_mask, a_input_ids, a_attn_mask):\n        q_outputs = self.question_encoder(q_input_ids, q_attn_mask)\n        a_outputs = self.answer_encoder(a_input_ids, a_attn_mask)\n\n        q_pooled = self.mean_pool(q_outputs, q_attn_mask)\n        a_pooled = self.mean_pool(a_outputs, a_attn_mask)\n        combined = torch.cat([q_pooled, a_pooled], dim=1)\n\n        return self.regressor(combined)\n\n    def mean_pool(self, outputs, mask):\n        token_embeds = outputs.last_hidden_state\n        mask_expanded = mask.unsqueeze(-1).expand(token_embeds.size()).float()\n        sum_embeds = torch.sum(token_embeds * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        return sum_embeds / sum_mask\n\n\nclass QADataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=256):\n        self.questions = df.apply(\n            lambda x: f\"{x['question_title']} {x['question_body']}\", axis=1\n        ).values\n        self.answers = df[\"answer\"].values\n        self.targets = (\n            df.iloc[:, 11:41].values\n            if \"question_asker_intent_understanding\" in df.columns\n            else None\n        )\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        q = str(self.questions[idx])\n        a = str(self.answers[idx])\n\n        q_tokens = self.tokenizer(\n            q,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        a_tokens = self.tokenizer(\n            a,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n\n        item = {\n            \"q_input_ids\": q_tokens[\"input_ids\"].squeeze(0),\n            \"q_attn_mask\": q_tokens[\"attention_mask\"].squeeze(0),\n            \"a_input_ids\": a_tokens[\"input_ids\"].squeeze(0),\n            \"a_attn_mask\": a_tokens[\"attention_mask\"].squeeze(0),\n        }\n\n        if self.targets is not None:\n            return item, torch.FloatTensor(self.targets[idx])\n        return item\n\n\ndef collate_fn(batch):\n    if isinstance(batch[0], tuple):\n        inputs = [x[0] for x in batch]\n        targets = torch.stack([x[1] for x in batch])\n        q_ids = torch.stack([x[\"q_input_ids\"] for x in inputs])\n        q_mask = torch.stack([x[\"q_attn_mask\"] for x in inputs])\n        a_ids = torch.stack([x[\"a_input_ids\"] for x in inputs])\n        a_mask = torch.stack([x[\"a_attn_mask\"] for x in inputs])\n        return q_ids, q_mask, a_ids, a_mask, targets\n    else:\n        q_ids = torch.stack([x[\"q_input_ids\"] for x in batch])\n        q_mask = torch.stack([x[\"q_attn_mask\"] for x in batch])\n        a_ids = torch.stack([x[\"a_input_ids\"] for x in batch])\n        a_mask = torch.stack([x[\"a_attn_mask\"] for x in batch])\n        return q_ids, q_mask, a_ids, a_mask\n\n\n# Prepare data and model\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n\nmodel = QAModel().to(device)\noptim = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\nloss_fn = nn.BCELoss()\n\n# Data loaders\ntrain_loader = DataLoader(\n    QADataset(train, tokenizer),\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=4,\n)\nval_loader = DataLoader(\n    QADataset(val, tokenizer), batch_size=32, collate_fn=collate_fn, num_workers=4\n)\n\n# Training\nbest_score = 0\nepochs = 8\ntotal_steps = len(train_loader) * epochs\nscheduler = get_linear_schedule_with_warmup(\n    optim, num_warmup_steps=0.1 * total_steps, num_training_steps=total_steps\n)\n\nfor epoch in range(epochs):\n    model.train()\n    for q_ids, q_mask, a_ids, a_mask, targets in train_loader:\n        q_ids = q_ids.to(device)\n        q_mask = q_mask.to(device)\n        a_ids = a_ids.to(device)\n        a_mask = a_mask.to(device)\n        targets = targets.to(device)\n\n        optim.zero_grad()\n        preds = model(q_ids, q_mask, a_ids, a_mask)\n        loss = loss_fn(preds, targets)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optim.step()\n        scheduler.step()\n\n    # Validation\n    model.eval()\n    val_preds, val_targets = [], []\n    with torch.no_grad():\n        for q_ids, q_mask, a_ids, a_mask, targets in val_loader:\n            q_ids = q_ids.to(device)\n            q_mask = q_mask.to(device)\n            a_ids = a_ids.to(device)\n            a_mask = a_mask.to(device)\n            batch_preds = model(q_ids, q_mask, a_ids, a_mask)\n            val_preds.append(batch_preds.cpu())\n            val_targets.append(targets.cpu())\n\n    val_preds = torch.cat(val_preds).numpy()\n    val_targets = torch.cat(val_targets).numpy()\n    scores = [\n        spearmanr(val_preds[:, i], val_targets[:, i]).correlation for i in range(30)\n    ]\n    score = np.nanmean(scores)\n    print(f\"Epoch {epoch+1} Val Score: {score:.4f}\")\n    if score > best_score:\n        best_score = score\n        torch.save(model.state_dict(), \"./working/best.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"./working/best.pt\"))\ntest_df = pd.read_csv(\"./input/test.csv\")\ntest_loader = DataLoader(\n    QADataset(test_df, tokenizer), batch_size=32, collate_fn=collate_fn\n)\n\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for q_ids, q_mask, a_ids, a_mask in test_loader:\n        q_ids = q_ids.to(device)\n        q_mask = q_mask.to(device)\n        a_ids = a_ids.to(device)\n        a_mask = a_mask.to(device)\n        batch_preds = model(q_ids, q_mask, a_ids, a_mask)\n        preds.append(batch_preds.cpu())\n\nsub = pd.DataFrame()\nsub[\"qa_id\"] = test_df[\"qa_id\"]\nsubmission_cols = pd.read_csv(\"./input/sample_submission.csv\").columns[1:]\nsub[submission_cols] = torch.cat(preds).numpy()\nos.makedirs(\"./submission\", exist_ok=True)\nsub.to_csv(\"./submission/submission.csv\", index=False)\n\nprint(f\"Final Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code successfully trains a DeBERTa-based model to predict subjective aspects of question-answer pairs, achieving a final validation Spearman correlation of 0.3761. The submission file is correctly saved as 'submission.csv' in the './submission/' directory. The validation metric indicates a moderate correlation between the predicted and actual values, suggesting room for improvement in model performance.",
            "is_bug": "False",
            "parent_index": 16,
            "node_level_analysis": "数据划分: hold-out 80/20 (train_test_split test_size=0.2, random_state=42)\n特征工程: 10个数值特征标准化(StandardScaler)，训练集fit→验证/测试transform\n类别编码: one-hot→类别索引(idxmax并提取序号，减1)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化→TensorDataset，DataLoader batch=4096，shuffle=True，num_workers=4\n模型构建: Embedding + ResNet-style MLP，输入10+4+16→512，blocks: 512→512 (×2)、512→256、256→256，输出256→7，含SE模块(缩减16倍)\n正则化: BatchNorm1d、Dropout(p=0.3/0.3/0.2/0.2)、weight_decay=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01)，OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n模型训练: 前向→损失→反向→更新→调度，epoch=25，batch_size=4096",
            "insights_from_parent": [
                "数据预处理：回退为分开对 question 与 answer 分别 token 化",
                "特征工程：分别对 Q/A 做 mask-aware mean pooling 后拼接特征",
                "模型选择：从单编码器改为双 DeBERTa 编码器，使两端专化表示",
                "参数调整：保持 lr=2e-5、wd=1e-4、BCELoss，调整 epoch 至 8",
                "训练策略：训练/数据管线改为处理分离输入，保留调度与梯度裁剪"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 24,
            "metric": 0.3372,
            "plan": "To improve the model's ability to capture interactions between questions and\nanswers, we'll switch from using separate encoders to a single encoder\nprocessing concatenated question-answer pairs. This allows cross-attention\nbetween both texts and leverages the CLS token for prediction. We'll also\nincrease sequence length to 512 for full context and adjust the model\narchitecture accordingly.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    AutoTokenizer,\n    AutoModel,\n    AdamW,\n    get_linear_schedule_with_warmup,\n)\nfrom scipy.stats import spearmanr\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass QAModel(nn.Module):\n    def __init__(self, model_name=\"microsoft/deberta-v3-base\", num_labels=30):\n        super().__init__()\n        self.encoder = AutoModel.from_pretrained(model_name)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.encoder.config.hidden_size, 512),\n            nn.GELU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_labels),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, input_ids, attn_mask):\n        outputs = self.encoder(input_ids, attn_mask)\n        cls_embedding = outputs.last_hidden_state[:, 0, :]\n        return self.regressor(cls_embedding)\n\n\nclass QADataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=512):\n        self.questions = df.apply(\n            lambda x: f\"{x['question_title']} {x['question_body']}\", axis=1\n        ).values\n        self.answers = df[\"answer\"].values\n        self.targets = (\n            df.iloc[:, 11:41].values\n            if \"question_asker_intent_understanding\" in df.columns\n            else None\n        )\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        q = str(self.questions[idx])\n        a = str(self.answers[idx])\n\n        tokens = self.tokenizer(\n            q,\n            a,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n\n        item = {\n            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n            \"attn_mask\": tokens[\"attention_mask\"].squeeze(0),\n        }\n\n        if self.targets is not None:\n            return item, torch.FloatTensor(self.targets[idx])\n        return item\n\n\ndef collate_fn(batch):\n    if isinstance(batch[0], tuple):\n        inputs = [x[0] for x in batch]\n        targets = torch.stack([x[1] for x in batch])\n        input_ids = torch.stack([x[\"input_ids\"] for x in inputs])\n        attn_mask = torch.stack([x[\"attn_mask\"] for x in inputs])\n        return input_ids, attn_mask, targets\n    else:\n        input_ids = torch.stack([x[\"input_ids\"] for x in batch])\n        attn_mask = torch.stack([x[\"attn_mask\"] for x in batch])\n        return input_ids, attn_mask\n\n\n# Prepare data and model\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n\nmodel = QAModel().to(device)\noptim = AdamW(model.parameters(), lr=3e-5, weight_decay=1e-4)\nloss_fn = nn.BCELoss()\n\n# Data loaders\ntrain_loader = DataLoader(\n    QADataset(train, tokenizer),\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=4,\n)\nval_loader = DataLoader(\n    QADataset(val, tokenizer), batch_size=32, collate_fn=collate_fn, num_workers=4\n)\n\n# Training\nbest_score = 0\nepochs = 10\ntotal_steps = len(train_loader) * epochs\nscheduler = get_linear_schedule_with_warmup(\n    optim, num_warmup_steps=0.1 * total_steps, num_training_steps=total_steps\n)\n\nfor epoch in range(epochs):\n    model.train()\n    for input_ids, attn_mask, targets in train_loader:\n        input_ids = input_ids.to(device)\n        attn_mask = attn_mask.to(device)\n        targets = targets.to(device)\n\n        optim.zero_grad()\n        preds = model(input_ids, attn_mask)\n        loss = loss_fn(preds, targets)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optim.step()\n        scheduler.step()\n\n    # Validation\n    model.eval()\n    val_preds, val_targets = [], []\n    with torch.no_grad():\n        for input_ids, attn_mask, targets in val_loader:\n            input_ids = input_ids.to(device)\n            attn_mask = attn_mask.to(device)\n            batch_preds = model(input_ids, attn_mask)\n            val_preds.append(batch_preds.cpu())\n            val_targets.append(targets.cpu())\n\n    val_preds = torch.cat(val_preds).numpy()\n    val_targets = torch.cat(val_targets).numpy()\n    scores = [\n        spearmanr(val_preds[:, i], val_targets[:, i]).correlation for i in range(30)\n    ]\n    score = np.nanmean(scores)\n    print(f\"Epoch {epoch+1} Val Score: {score:.4f}\")\n    if score > best_score:\n        best_score = score\n        torch.save(model.state_dict(), \"./working/best.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"./working/best.pt\"))\ntest_df = pd.read_csv(\"./input/test.csv\")\ntest_loader = DataLoader(\n    QADataset(test_df, tokenizer), batch_size=32, collate_fn=collate_fn\n)\n\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for input_ids, attn_mask in test_loader:\n        input_ids = input_ids.to(device)\n        attn_mask = attn_mask.to(device)\n        batch_preds = model(input_ids, attn_mask)\n        preds.append(batch_preds.cpu())\n\nsub = pd.DataFrame()\nsub[\"qa_id\"] = test_df[\"qa_id\"]\nsubmission_cols = pd.read_csv(\"./input/sample_submission.csv\").columns[1:]\nsub[submission_cols] = torch.cat(preds).numpy()\nos.makedirs(\"./submission\", exist_ok=True)\nsub.to_csv(\"./submission/submission.csv\", index=False)\n\nprint(f\"Final Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The training script successfully executed and produced a submission.csv file in the ./submission/ directory. The model achieved a final validation Spearman correlation score of 0.3372, indicating a moderate level of correlation between the predicted and true values. The goal is to maximize the Spearman's correlation coefficient, and the execution log shows a steady improvement in validation scores across epochs, suggesting effective model training.",
            "is_bug": "False",
            "parent_index": 21,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 数值特征标准化(StandardScaler)，one-hot→索引(idxmax→减1)\n类别编码: one-hot→索引(idxmax−1)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化(TensorDataset)、DataLoader(batch=4096, shuffle=True(train), batch=4096(val), num_workers=4)\n模型构建: Embedding + ResNet-MLP(输入10+4+16→512，blocks: 512→512(drop0.3),512→512(drop0.3),512→256(drop0.2),256→256(drop0.2)，SE)，输出256→7\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01)、OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)、epochs=25\n模型训练: 前向→损失→反向→更新→调度",
            "insights_from_parent": [
                "数据预处理：再次合并 question+answer 输入 encoder，max_len 增至 512 以容纳更长上下文",
                "特征工程：由 mask-mean 回退为使用 CLS token 作为序列表示",
                "模型选择：单一 DeBERTa 编码器 + 更深更宽的回归头（多层 FC 与更高 dropout）",
                "参数调整：lr 提升至 3e-5，增大 dropout，保持 BCELoss，模型容量与正则化同时提高",
                "训练策略：epochs 增至 10，保留调度与梯度裁剪以适配更大模型和更长序列"
            ]
        }
    ],
    [
        {
            "demo_id": "google-quest-challenge",
            "node_index": 5,
            "metric": 0.3389,
            "plan": "To address this multi-target regression task, we'll use a pre-trained BERT model\nto encode the combined text from questions and answers, followed by a regression\nhead to predict all 30 targets simultaneously. We'll leverage transfer learning\nfrom BERT's language understanding capabilities while ensuring predictions stay\nwithin [0,1] through output clipping.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load and prepare data\ntrain_df = pd.read_csv(\"input/train.csv\")\ntest_df = pd.read_csv(\"input/test.csv\")\nsample_sub = pd.read_csv(\"input/sample_submission.csv\")\ntarget_cols = sample_sub.columns[1:].tolist()\n\n\n# Combine text features\ndef combine_text(row):\n    return f\"{row['question_title']} [SEP] {row['question_body']} [SEP] {row['answer']}\"\n\n\ntrain_df[\"combined_text\"] = train_df.apply(combine_text, axis=1)\ntest_df[\"combined_text\"] = test_df.apply(combine_text, axis=1)\n\n# Split into train/validation\nX_train, X_val, y_train, y_val = train_test_split(\n    train_df[\"combined_text\"], train_df[target_cols], test_size=0.2, random_state=42\n)\n\n# BERT tokenization\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nmax_length = 512\n\n\ndef tokenize(texts):\n    return tokenizer(\n        texts.tolist(),\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\",\n    )\n\n\ntrain_enc = tokenize(X_train)\nval_enc = tokenize(X_val)\ntest_enc = tokenize(test_df[\"combined_text\"])\n\n\n# Dataset preparation\nclass QADataset(Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            \"input_ids\": self.encodings[\"input_ids\"][idx],\n            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.tensor(\n                self.labels.iloc[idx].values, dtype=torch.float\n            )\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n\ntrain_dataset = QADataset(train_enc, y_train)\nval_dataset = QADataset(val_enc, y_val)\ntest_dataset = QADataset(test_enc)\n\n\n# Model architecture\nclass BertMultiTarget(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.bert.config.hidden_size, 256), nn.ReLU(), nn.Linear(256, 30)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = outputs.last_hidden_state[:, 0, :]\n        pooled = self.dropout(pooled)\n        return torch.sigmoid(self.regressor(pooled))\n\n\nmodel = BertMultiTarget().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\nloss_fn = nn.MSELoss()\n\n# Training setup\nbatch_size = 32\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\n# Training loop\nbest_score = 0\nfor epoch in range(4):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attn_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(input_ids, attn_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    # Validation\n    model.eval()\n    preds, truths = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attn_mask = batch[\"attention_mask\"].to(device)\n            outputs = model(input_ids, attn_mask).cpu().numpy()\n            preds.append(outputs)\n            truths.append(batch[\"labels\"].numpy())\n\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    spearman_scores = [\n        spearmanr(preds[:, i], truths[:, i]).correlation for i in range(30)\n    ]\n    mean_spearman = np.nanmean(spearman_scores)\n    print(\n        f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Spearman: {mean_spearman:.4f}\"\n    )\n\n    if mean_spearman > best_score:\n        best_score = mean_spearman\n        torch.save(model.state_dict(), \"best_model.pt\")\n\n# Final prediction\nmodel.load_state_dict(torch.load(\"best_model.pt\"))\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attn_mask = batch[\"attention_mask\"].to(device)\n        outputs = model(input_ids, attn_mask).cpu().numpy()\n        test_preds.append(outputs)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=target_cols)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nsubmission.to_csv(\"submission/submission.csv\", index=False)\n\nprint(f\"\\nFinal Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code successfully trained a BERT model to predict subjective question-answering aspects, achieving a final validation Spearman correlation of 0.3389. The predictions are saved in the required 'submission.csv' format in the './submission/' directory. The execution log shows no errors or bugs during the process.",
            "is_bug": "False",
            "parent_index": 0,
            "node_level_analysis": "数据划分: hold-out 80/20, test_size=0.2, random_state=42\n特征工程: 数值标准化 StandardScaler（fit on train, transform val/test）\n类别编码: one-hot→索引（Wilderness、Soil 从独热列取 idx -1）\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化、DataLoader，batch=4096，shuffle（train），num_workers=4\n模型构建: Embedding + ResNet-MLP（输入 10+4+16→512，blocks: 512→512, 512→512, 512→256, 256→256，输出 256→7），含 SE 模块与 shortcut\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01)，OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n模型训练: 前向→损失→反向→更新→调度, epoch=25",
            "insights_from_parent": [
                "采用BERT编码并做多目标回归"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 8,
            "metric": 0.3548,
            "plan": "To improve the model's ability to capture distinct features from questions and\nanswers, we'll implement a Siamese architecture with separate RoBERTa encoders\nfor each component. This allows the model to learn specialized representations\nand their interactions, which is particularly important since 15 targets are\nquestion-specific and 15 are answer-specific. The model will process question\n(title + body) and answer text separately, then combine their embeddings for\nprediction.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaTokenizer, RobertaModel\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load and prepare data\ntrain_df = pd.read_csv(\"input/train.csv\")\ntest_df = pd.read_csv(\"input/test.csv\")\nsample_sub = pd.read_csv(\"input/sample_submission.csv\")\ntarget_cols = sample_sub.columns[1:].tolist()\n\n# Prepare separate question and answer text\ntrain_df[\"question_text\"] = train_df[\"question_title\"] + \" \" + train_df[\"question_body\"]\ntrain_df[\"answer_text\"] = train_df[\"answer\"]\ntest_df[\"question_text\"] = test_df[\"question_title\"] + \" \" + test_df[\"question_body\"]\ntest_df[\"answer_text\"] = test_df[\"answer\"]\n\n# Split into train/validation\nX_train_q, X_val_q, X_train_a, X_val_a, y_train, y_val = train_test_split(\n    train_df[\"question_text\"],\n    train_df[\"answer_text\"],\n    train_df[target_cols],\n    test_size=0.2,\n    random_state=42,\n)\n\n# RoBERTa tokenization\ntokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\nmax_length = 256\n\n\ndef tokenize_qa(questions, answers):\n    q_enc = tokenizer.batch_encode_plus(\n        questions.tolist(),\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\",\n    )\n    a_enc = tokenizer.batch_encode_plus(\n        answers.tolist(),\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\",\n    )\n    return q_enc, a_enc\n\n\ntrain_q_enc, train_a_enc = tokenize_qa(X_train_q, X_train_a)\nval_q_enc, val_a_enc = tokenize_qa(X_val_q, X_val_a)\ntest_q_enc, test_a_enc = tokenize_qa(test_df[\"question_text\"], test_df[\"answer_text\"])\n\n\n# Dataset preparation\nclass QADataset(Dataset):\n    def __init__(self, q_enc, a_enc, labels=None):\n        self.q_enc = q_enc\n        self.a_enc = a_enc\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            \"q_input_ids\": self.q_enc[\"input_ids\"][idx],\n            \"q_attention_mask\": self.q_enc[\"attention_mask\"][idx],\n            \"a_input_ids\": self.a_enc[\"input_ids\"][idx],\n            \"a_attention_mask\": self.a_enc[\"attention_mask\"][idx],\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.tensor(\n                self.labels.iloc[idx].values, dtype=torch.float\n            )\n        return item\n\n    def __len__(self):\n        return len(self.q_enc[\"input_ids\"])\n\n\ntrain_dataset = QADataset(train_q_enc, train_a_enc, y_train)\nval_dataset = QADataset(val_q_enc, val_a_enc, y_val)\ntest_dataset = QADataset(test_q_enc, test_a_enc)\n\n\n# Siamese RoBERTa model\nclass SiameseRoberta(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.roberta = RobertaModel.from_pretrained(\"roberta-base\")\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(2 * self.roberta.config.hidden_size, 512),\n            nn.GELU(),\n            nn.LayerNorm(512),\n            nn.Dropout(0.2),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, q_ids, q_mask, a_ids, a_mask):\n        q_out = self.roberta(q_ids, attention_mask=q_mask)[0][:, 0, :]\n        a_out = self.roberta(a_ids, attention_mask=a_mask)[0][:, 0, :]\n        combined = torch.cat([q_out, a_out], dim=1)\n        return torch.sigmoid(self.regressor(self.dropout(combined)))\n\n\nmodel = SiameseRoberta().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\nloss_fn = nn.MSELoss()\n\n# Training setup\nbatch_size = 32\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\n# Training loop\nbest_score = 0\nfor epoch in range(5):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        q_ids = batch[\"q_input_ids\"].to(device)\n        q_mask = batch[\"q_attention_mask\"].to(device)\n        a_ids = batch[\"a_input_ids\"].to(device)\n        a_mask = batch[\"a_attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(q_ids, q_mask, a_ids, a_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        total_loss += loss.item()\n\n    # Validation\n    model.eval()\n    preds, truths = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            q_ids = batch[\"q_input_ids\"].to(device)\n            q_mask = batch[\"q_attention_mask\"].to(device)\n            a_ids = batch[\"a_input_ids\"].to(device)\n            a_mask = batch[\"a_attention_mask\"].to(device)\n\n            outputs = model(q_ids, q_mask, a_ids, a_mask).cpu().numpy()\n            preds.append(outputs)\n            truths.append(batch[\"labels\"].numpy())\n\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    spearman_scores = [\n        spearmanr(preds[:, i], truths[:, i]).correlation for i in range(30)\n    ]\n    mean_spearman = np.nanmean(spearman_scores)\n    print(\n        f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Spearman: {mean_spearman:.4f}\"\n    )\n\n    if mean_spearman > best_score:\n        best_score = mean_spearman\n        torch.save(model.state_dict(), \"best_model.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"best_model.pt\"))\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        q_ids = batch[\"q_input_ids\"].to(device)\n        q_mask = batch[\"q_attention_mask\"].to(device)\n        a_ids = batch[\"a_input_ids\"].to(device)\n        a_mask = batch[\"a_attention_mask\"].to(device)\n\n        outputs = model(q_ids, q_mask, a_ids, a_mask).cpu().numpy()\n        test_preds.append(outputs)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=target_cols)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nsubmission.to_csv(\"submission/submission.csv\", index=False)\n\nprint(f\"\\nFinal Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code successfully trains a Siamese RoBERTa model to predict subjective aspects of question-answer pairs, achieving a final validation Spearman correlation of 0.3548. The model's predictions are saved in the required submission format, indicating that the execution was successful and without any bugs. The metric, Spearman correlation, is maximized, indicating better performance with higher values.",
            "is_bug": "False",
            "parent_index": 5,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 标准化(StandardScaler) 对数值特征\n类别编码: 一热→索引 (Wilderness 1-4→0-3, Soil 1-40→0-39)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化 + DataLoader（batch=4096, shuffle=True, num_workers=4）\n模型构建: Embedding + ResNet-like MLP（输入 10+4+16→512，blocks 512→512→256→256，输出 256→7），SE 注意力\n正则化: BatchNorm, Dropout(p=0.3/0.2), 权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01) + OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n模型训练: 前向→损失→反向→更新→调度，epoch=25",
            "insights_from_parent": [
                "数据预处理：将问答拆分为 question_text 与 answer_text，分别 token 化，max_length 从 512 降到 256",
                "特征工程：分别编码问题和答案以保留独立表示，取消合并文本特征",
                "模型选择：由单分支 BERT 转为 Siamese RoBERTa 双分支并拼接表示以回归",
                "参数调整：学习率从 3e-5 降至 2e-5，加入 weight_decay，使用 GELU 与 LayerNorm",
                "训练策略：训练轮次增至 5，加入梯度裁剪，保持 batch_size=32"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 11,
            "metric": 0.3921,
            "plan": "To improve the model's ability to capture interactions between question-answer\npairs and directly optimize for the evaluation metric, we'll implement two key\nchanges: 1) Switch from a Siamese architecture to a cross-encoder that processes\nconcatenated question-answer text, enabling full attention between both\ncomponents, and 2) Replace MSE loss with Pearson correlation loss to directly\noptimize for correlation metrics. This approach allows deeper contextual\nunderstanding between paired texts and aligns optimization with the\ncompetition's evaluation metric.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaTokenizer, RobertaModel\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load and prepare data\ntrain_df = pd.read_csv(\"input/train.csv\")\ntest_df = pd.read_csv(\"input/test.csv\")\nsample_sub = pd.read_csv(\"input/sample_submission.csv\")\ntarget_cols = sample_sub.columns[1:].tolist()\n\n# Prepare combined question-answer text\ntrain_df[\"question_text\"] = train_df[\"question_title\"] + \" \" + train_df[\"question_body\"]\ntest_df[\"question_text\"] = test_df[\"question_title\"] + \" \" + test_df[\"question_body\"]\ntrain_df[\"combined_text\"] = train_df[\"question_text\"] + \" </s> \" + train_df[\"answer\"]\ntest_df[\"combined_text\"] = test_df[\"question_text\"] + \" </s> \" + test_df[\"answer\"]\n\n# Split into train/validation\nX_train, X_val, y_train, y_val = train_test_split(\n    train_df[\"combined_text\"],\n    train_df[target_cols],\n    test_size=0.2,\n    random_state=42,\n)\n\n# RoBERTa tokenization\ntokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\nmax_length = 512\n\n\ndef tokenize(texts):\n    return tokenizer.batch_encode_plus(\n        texts,\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\",\n    )\n\n\ntrain_enc = tokenize(X_train.tolist())\nval_enc = tokenize(X_val.tolist())\ntest_enc = tokenize(test_df[\"combined_text\"].tolist())\n\n\n# Dataset preparation\nclass QADataset(Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            \"input_ids\": self.encodings[\"input_ids\"][idx],\n            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.tensor(\n                self.labels.iloc[idx].values, dtype=torch.float\n            )\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n\ntrain_dataset = QADataset(train_enc, y_train)\nval_dataset = QADataset(val_enc, y_val)\ntest_dataset = QADataset(test_enc)\n\n\n# Pearson correlation loss\nclass PearsonLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.eps = 1e-6\n\n    def forward(self, preds, targets):\n        preds_mean = preds.mean(dim=0, keepdim=True)\n        targets_mean = targets.mean(dim=0, keepdim=True)\n\n        centered_preds = preds - preds_mean\n        centered_targets = targets - targets_mean\n\n        covariance = (centered_preds * centered_targets).mean(dim=0)\n        preds_std = torch.sqrt(centered_preds.pow(2).mean(dim=0) + self.eps)\n        targets_std = torch.sqrt(centered_targets.pow(2).mean(dim=0) + self.eps)\n\n        pearson = covariance / (preds_std * targets_std + self.eps)\n        return 1 - pearson.mean()\n\n\n# Cross-encoder model\nclass CrossEncoderRoberta(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.roberta = RobertaModel.from_pretrained(\"roberta-base\")\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.roberta.config.hidden_size, 512),\n            nn.GELU(),\n            nn.LayerNorm(512),\n            nn.Dropout(0.2),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        return torch.sigmoid(self.regressor(self.dropout(pooled_output)))\n\n\nmodel = CrossEncoderRoberta().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\nloss_fn = PearsonLoss()\n\n# Training setup\nbatch_size = 32\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\n# Training loop\nbest_score = 0\nfor epoch in range(5):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(input_ids, attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        total_loss += loss.item()\n\n    # Validation\n    model.eval()\n    preds, truths = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n\n            outputs = model(input_ids, attention_mask).cpu().numpy()\n            preds.append(outputs)\n            truths.append(batch[\"labels\"].numpy())\n\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    spearman_scores = [\n        spearmanr(preds[:, i], truths[:, i]).correlation for i in range(30)\n    ]\n    mean_spearman = np.nanmean(spearman_scores)\n    print(\n        f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Spearman: {mean_spearman:.4f}\"\n    )\n\n    if mean_spearman > best_score:\n        best_score = mean_spearman\n        torch.save(model.state_dict(), \"best_model.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"best_model.pt\"))\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n\n        outputs = model(input_ids, attention_mask).cpu().numpy()\n        test_preds.append(outputs)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=target_cols)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nsubmission.to_csv(\"submission/submission.csv\", index=False)\n\nprint(f\"\\nFinal Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code successfully trains a RoBERTa-based model to predict subjective aspects of question-answer pairs. It achieves a final validation Spearman correlation of 0.3921, indicating a moderate level of prediction accuracy. The predictions are saved in a 'submission.csv' file, as required by the competition instructions.",
            "is_bug": "False",
            "parent_index": 8,
            "node_level_analysis": "数据划分: hold-out 80/20，random_state=42\n特征工程: 数值特征标准化(StandardScaler)应用于10个数值列\n类别编码: one-hot→索引（Wilderness、Soil）\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化、DataLoader(batch=4096, shuffle=True（train），num_workers=4)\n模型构建: Embedding + ResNet-MLP，输入10+4+16→Linear→512，blocks 512→512→256→256，输出256→7，ResidualBlock含SE模块\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01)、OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n训练循环: 前向→损失→反向→更新→调度",
            "insights_from_parent": [
                "数据预处理：由双分支改为将 question 与 answer 合并为一个输入（合并文本并加分隔符）",
                "特征工程：对联合文本进行 tokenization，max_length 恢复到 512 以容纳更长上下文",
                "模型选择：由 Siamese 转为 Cross-encoder RoBERTa，允许问题与答案间的全注意力交互",
                "参数调整：损失函数由 MSE 换为 Pearson 相关性损失以对齐评估指标，优化器保持 AdamW lr=2e-5",
                "训练策略：直接以相关性为训练目标并在验证时计算 Spearman 作为度量"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 12,
            "metric": null,
            "plan": "To improve the model's performance, we'll upgrade to DeBERTa-v3-large for its\nsuperior attention mechanisms and process questions and answers as separate\nsegments to better capture their semantic relationship. This allows the model to\nleverage the inherent structure of Q&A pairs, enhancing its ability to predict\nsubjective labels accurately.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load and prepare data\ntrain_df = pd.read_csv(\"input/train.csv\")\ntest_df = pd.read_csv(\"input/test.csv\")\nsample_sub = pd.read_csv(\"input/sample_submission.csv\")\ntarget_cols = sample_sub.columns[1:].tolist()\n\n# Prepare separate question and answer text\ntrain_df[\"question_text\"] = train_df[\"question_title\"] + \" \" + train_df[\"question_body\"]\ntest_df[\"question_text\"] = test_df[\"question_title\"] + \" \" + test_df[\"question_body\"]\n\n# Split into train/validation with separate Q&A\nX_train_q, X_val_q, X_train_a, X_val_a, y_train, y_val = train_test_split(\n    train_df[\"question_text\"],\n    train_df[\"answer\"],\n    train_df[target_cols],\n    test_size=0.2,\n    random_state=42,\n)\n\n# DeBERTa tokenization with separate segments\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\nmax_length = 512\n\n\ndef tokenize(questions, answers):\n    return tokenizer.batch_encode_plus(\n        list(zip(questions, answers)),\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation=\"only_second\",\n        return_tensors=\"pt\",\n    )\n\n\ntrain_enc = tokenize(X_train_q.tolist(), X_train_a.tolist())\nval_enc = tokenize(X_val_q.tolist(), X_val_a.tolist())\ntest_enc = tokenize(test_df[\"question_text\"].tolist(), test_df[\"answer\"].tolist())\n\n\n# Dataset preparation\nclass QADataset(Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            \"input_ids\": self.encodings[\"input_ids\"][idx],\n            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.tensor(\n                self.labels.iloc[idx].values, dtype=torch.float\n            )\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n\ntrain_dataset = QADataset(train_enc, y_train)\nval_dataset = QADataset(val_enc, y_val)\ntest_dataset = QADataset(test_enc)\n\n\n# Pearson correlation loss\nclass PearsonLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.eps = 1e-6\n\n    def forward(self, preds, targets):\n        preds_mean = preds.mean(dim=0, keepdim=True)\n        targets_mean = targets.mean(dim=0, keepdim=True)\n\n        centered_preds = preds - preds_mean\n        centered_targets = targets - targets_mean\n\n        covariance = (centered_preds * centered_targets).mean(dim=0)\n        preds_std = torch.sqrt(centered_preds.pow(2).mean(dim=0) + self.eps)\n        targets_std = torch.sqrt(centered_targets.pow(2).mean(dim=0) + self.eps)\n\n        pearson = covariance / (preds_std * targets_std + self.eps)\n        return 1 - pearson.mean()\n\n\n# DeBERTa-based model\nclass CrossEncoderDeBERTa(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.deberta = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.deberta.config.hidden_size, 512),\n            nn.GELU(),\n            nn.LayerNorm(512),\n            nn.Dropout(0.2),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.deberta(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        return torch.sigmoid(self.regressor(self.dropout(pooled_output)))\n\n\nmodel = CrossEncoderDeBERTa().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\nloss_fn = PearsonLoss()\n\n# Training setup\nbatch_size = 16  # Reduced for larger model\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\n# Training loop\nbest_score = 0\nfor epoch in range(5):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(input_ids, attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        total_loss += loss.item()\n\n    # Validation\n    model.eval()\n    preds, truths = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n\n            outputs = model(input_ids, attention_mask).cpu().numpy()\n            preds.append(outputs)\n            truths.append(batch[\"labels\"].numpy())\n\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    spearman_scores = [\n        spearmanr(preds[:, i], truths[:, i]).correlation for i in range(30)\n    ]\n    mean_spearman = np.nanmean(spearman_scores)\n    print(\n        f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Spearman: {mean_spearman:.4f}\"\n    )\n\n    if mean_spearman > best_score:\n        best_score = mean_spearman\n        torch.save(model.state_dict(), \"best_model.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"best_model.pt\"))\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n\n        outputs = model(input_ids, attention_mask).cpu().numpy()\n        test_preds.append(outputs)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=target_cols)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nsubmission.to_csv(\"submission/submission.csv\", index=False)\n\nprint(f\"\\nFinal Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code execution failed due to a truncation error during tokenization, indicating a bug in handling sequences that are too short for the specified max_length. As a result, the submission.csv file was not produced in the required directory. The validation metric could not be calculated due to the execution failure.",
            "is_bug": "True",
            "parent_index": 11,
            "node_level_analysis": "数据划分: hold-out 20% test_size=0.2, random_state=42\n特征工程: 数值列 StandardScaler 标准化（fit_transform/transform）\n类别编码: 从 one-hot 提取类别索引（idxmax→序号-1）\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化(torch.tensor dtype=torch.float32)→TensorDataset、DataLoader batch=4096, shuffle=True, num_workers=4\n模型构建: Embedding + ResNet-MLP（输入 Linear(10+4+16→512)，残差块 512→512,512→512,512→256,256→256，输出 Linear(256→7)）+ SE模块\n正则化: BatchNorm1d、Dropout(p=0.3/0.3/0.2/0.2)、weight_decay=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, weight_decay=0.01, OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n训练循环: epoch=25，前向→损失→反向→更新→调度",
            "insights_from_parent": [
                "数据预处理：切换到 DeBERTa-v3-large，使用成对编码（questions, answers）并采用 only_second 截断策略",
                "特征工程：利用更强的预训练模型 DeBERTa 以期改善注意力建模和语义表达",
                "模型选择：将 RoBERTa 替换为 microsoft/deberta-v3-large，模型主体升级",
                "参数调整：为适应大模型将 batch_size 从 32 降至 16，保持 lr=2e-5 与 weight_decay",
                "训练策略：在资源受限下通过减小 batch 以兼顾显存与性能，损失继续用 PearsonLoss"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 17,
            "metric": 0.3945,
            "plan": "The error occurs because the tokenizer's truncation strategy (\"only_second\")\nfails when answers are too short. Changing to \"longest_first\" allows truncating\nthe longer sequence when needed. Also, ensure proper directory creation for\nsubmission.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Create submission directory if needed\nos.makedirs(\"submission\", exist_ok=True)\n\n# Load and prepare data\ntrain_df = pd.read_csv(\"input/train.csv\")\ntest_df = pd.read_csv(\"input/test.csv\")\nsample_sub = pd.read_csv(\"input/sample_submission.csv\")\ntarget_cols = sample_sub.columns[1:].tolist()\n\n# Prepare question-answer pairs\ntrain_df[\"question_text\"] = train_df[\"question_title\"] + \" \" + train_df[\"question_body\"]\ntest_df[\"question_text\"] = test_df[\"question_title\"] + \" \" + test_df[\"question_body\"]\n\n# Split data\nX_train_q, X_val_q, X_train_a, X_val_a, y_train, y_val = train_test_split(\n    train_df[\"question_text\"],\n    train_df[\"answer\"],\n    train_df[target_cols],\n    test_size=0.2,\n    random_state=42,\n)\n\n# Fixed tokenization with safer truncation\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\nmax_length = 512\n\n\ndef tokenize(questions, answers):\n    return tokenizer.batch_encode_plus(\n        list(zip(questions, answers)),\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation=\"longest_first\",  # Changed from \"only_second\"\n        return_tensors=\"pt\",\n    )\n\n\ntrain_enc = tokenize(X_train_q.tolist(), X_train_a.tolist())\nval_enc = tokenize(X_val_q.tolist(), X_val_a.tolist())\ntest_enc = tokenize(test_df[\"question_text\"].tolist(), test_df[\"answer\"].tolist())\n\n\nclass QADataset(Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            \"input_ids\": self.encodings[\"input_ids\"][idx],\n            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.tensor(\n                self.labels.iloc[idx].values, dtype=torch.float\n            )\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n\ntrain_dataset = QADataset(train_enc, y_train)\nval_dataset = QADataset(val_enc, y_val)\ntest_dataset = QADataset(test_enc)\n\n\nclass PearsonLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.eps = 1e-6\n\n    def forward(self, preds, targets):\n        preds_mean = preds.mean(dim=0, keepdim=True)\n        targets_mean = targets.mean(dim=0, keepdim=True)\n\n        centered_preds = preds - preds_mean\n        centered_targets = targets - targets_mean\n\n        covariance = (centered_preds * centered_targets).mean(dim=0)\n        preds_std = torch.sqrt(centered_preds.pow(2).mean(dim=0) + self.eps)\n        targets_std = torch.sqrt(centered_targets.pow(2).mean(dim=0) + self.eps)\n\n        pearson = covariance / (preds_std * targets_std + self.eps)\n        return 1 - pearson.mean()\n\n\nclass CrossEncoderDeBERTa(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.deberta = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.deberta.config.hidden_size, 512),\n            nn.GELU(),\n            nn.LayerNorm(512),\n            nn.Dropout(0.2),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.deberta(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        return torch.sigmoid(self.regressor(self.dropout(pooled_output)))\n\n\nmodel = CrossEncoderDeBERTa().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\nloss_fn = PearsonLoss()\n\nbatch_size = 16\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\nbest_score = 0\nfor epoch in range(5):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(input_ids, attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        total_loss += loss.item()\n\n    # Validation\n    model.eval()\n    preds, truths = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            outputs = model(input_ids, attention_mask).cpu().numpy()\n            preds.append(outputs)\n            truths.append(batch[\"labels\"].numpy())\n\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    spearman_scores = [\n        spearmanr(preds[:, i], truths[:, i]).correlation for i in range(30)\n    ]\n    mean_spearman = np.nanmean(spearman_scores)\n    print(\n        f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Spearman: {mean_spearman:.4f}\"\n    )\n\n    if mean_spearman > best_score:\n        best_score = mean_spearman\n        torch.save(model.state_dict(), \"best_model.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"best_model.pt\"))\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        outputs = model(input_ids, attention_mask).cpu().numpy()\n        test_preds.append(outputs)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=target_cols)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nsubmission.to_csv(\"submission/submission.csv\", index=False)\n\nprint(f\"\\nFinal Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code successfully executed and trained a model to predict 30 labels for question-answer pairs, achieving a final validation Spearman correlation of 0.3945. The model uses the DeBERTa transformer model and a custom Pearson loss function to optimize predictions. The predictions are saved in a 'submission.csv' file, as required.",
            "is_bug": "False",
            "parent_index": 12,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 数值标准化(StandardScaler) 对10个数值特征\n类别编码: one-hot→索引 (Wilderness, Soil)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化、DataLoader batch=4096、shuffle=True(训练)、num_workers=4\n模型构建: Embedding + ResNet-MLP，输入10+4+16→512，blocks 512→512→256→256，输出256→7，含SE模块\n正则化: BatchNorm、Dropout(p=0.3/0.2)、权重衰减=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01)、OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n训练循环: 前向→损失→反向→更新→调度，epoch=25",
            "insights_from_parent": [
                "数据预处理：修复 tokenizer 截断策略，由 only_second 改为 longest_first，避免短答案导致错误",
                "特征工程：无实质性变化（仅截断策略更改）",
                "模型选择：仍使用 DeBERTa-v3-large，模型结构未变",
                "参数调整：无超参调整，新增确保提交目录存在的文件操作",
                "训练策略：训练流程不变，仅修复输入处理以保证稳定运行"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 18,
            "metric": null,
            "plan": "To improve the model's performance by directly optimizing for the competition\nmetric, we'll implement two key changes: 1) Replace Pearson loss with a\ndifferentiable Spearman correlation approximation using soft ranking, and 2) Add\nattention pooling to better capture contextual information. The Spearman loss\naligns training with evaluation metric, while attention pooling helps model\nfocus on relevant text segments.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nimport torchsort\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nos.makedirs(\"submission\", exist_ok=True)\n\n# Load data\ntrain_df = pd.read_csv(\"input/train.csv\")\ntest_df = pd.read_csv(\"input/test.csv\")\ntarget_cols = pd.read_csv(\"input/sample_submission.csv\").columns[1:].tolist()\n\n# Prepare text inputs with special tokens\ntrain_df[\"text\"] = (\n    \"[Q] \"\n    + train_df[\"question_title\"]\n    + \" [SEP] \"\n    + train_df[\"question_body\"]\n    + \" [A] \"\n    + train_df[\"answer\"]\n)\ntest_df[\"text\"] = (\n    \"[Q] \"\n    + test_df[\"question_title\"]\n    + \" [SEP] \"\n    + test_df[\"question_body\"]\n    + \" [A] \"\n    + test_df[\"answer\"]\n)\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(\n    train_df[\"text\"], train_df[target_cols], test_size=0.2, random_state=42\n)\n\n# Tokenization\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\nmax_length = 512\n\n\ndef tokenize(texts):\n    return tokenizer.batch_encode_plus(\n        texts,\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\",\n        add_special_tokens=True,\n    )\n\n\ntrain_enc = tokenize(X_train.tolist())\nval_enc = tokenize(X_val.tolist())\ntest_enc = tokenize(test_df[\"text\"].tolist())\n\n\nclass QADataset(Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            \"input_ids\": self.encodings[\"input_ids\"][idx],\n            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.tensor(\n                self.labels.iloc[idx].values, dtype=torch.float\n            )\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n\ntrain_dataset = QADataset(train_enc, y_train)\nval_dataset = QADataset(val_enc, y_val)\ntest_dataset = QADataset(test_enc)\n\n\nclass SpearmanLoss(nn.Module):\n    def __init__(self, regularization=\"l2\", regularization_strength=1.0):\n        super().__init__()\n        self.regularization = regularization\n        self.eps = 1e-7\n        self.regularization_strength = regularization_strength\n\n    def forward(self, preds, targets):\n        preds_rank = torchsort.soft_rank(\n            preds,\n            regularization=self.regularization,\n            regularization_strength=self.regularization_strength,\n        )\n        targets_rank = torchsort.soft_rank(\n            targets,\n            regularization=self.regularization,\n            regularization_strength=self.regularization_strength,\n        )\n\n        preds_rank = preds_rank - preds_rank.mean(dim=0)\n        targets_rank = targets_rank - targets_rank.mean(dim=0)\n\n        cov = (preds_rank * targets_rank).mean(dim=0)\n        preds_std = torch.sqrt((preds_rank**2).mean(dim=0) + self.eps)\n        targets_std = torch.sqrt((targets_rank**2).mean(dim=0) + self.eps)\n\n        spearman = cov / (preds_std * targets_std + self.eps)\n        return 1 - spearman.mean()\n\n\nclass AttentionPooling(nn.Module):\n    def __init__(self, hidden_size):\n        super().__init__()\n        self.attn = nn.Sequential(\n            nn.Linear(hidden_size, 256), nn.Tanh(), nn.Linear(256, 1), nn.Softmax(dim=1)\n        )\n\n    def forward(self, hidden_states, attention_mask):\n        scores = self.attn(hidden_states).squeeze(-1)\n        scores[~attention_mask.bool()] = -1e4\n        weights = torch.softmax(scores, dim=1)\n        return (hidden_states * weights.unsqueeze(-1)).sum(dim=1)\n\n\nclass CrossEncoderDeBERTa(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.deberta = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n        self.attention_pooling = AttentionPooling(self.deberta.config.hidden_size)\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.deberta.config.hidden_size, 512),\n            nn.GELU(),\n            nn.LayerNorm(512),\n            nn.Dropout(0.2),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.deberta(input_ids, attention_mask=attention_mask)\n        pooled = self.attention_pooling(outputs.last_hidden_state, attention_mask)\n        return torch.sigmoid(self.regressor(self.dropout(pooled)))\n\n\nmodel = CrossEncoderDeBERTa().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n    optimizer, T_0=100, T_mult=1\n)\nloss_fn = SpearmanLoss()\n\nbatch_size = 16\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\nbest_score = 0\nfor epoch in range(5):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(input_ids, attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        total_loss += loss.item()\n\n    # Validation\n    model.eval()\n    preds, truths = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            outputs = model(input_ids, attention_mask).cpu().numpy()\n            preds.append(outputs)\n            truths.append(batch[\"labels\"].numpy())\n\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    spearman_scores = [\n        spearmanr(preds[:, i], truths[:, i]).correlation for i in range(30)\n    ]\n    mean_spearman = np.nanmean(spearman_scores)\n    print(\n        f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Spearman: {mean_spearman:.4f}\"\n    )\n\n    if mean_spearman > best_score:\n        best_score = mean_spearman\n        torch.save(model.state_dict(), \"best_model.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"best_model.pt\"))\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        outputs = model(input_ids, attention_mask).cpu().numpy()\n        test_preds.append(outputs)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=target_cols)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nsubmission.to_csv(\"submission/submission.csv\", index=False)\n\nprint(f\"\\nFinal Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code execution failed due to a runtime error related to gradient computation in PyTorch. The error message suggests that an in-place operation modified a variable needed for gradient computation, causing the backward pass to fail. As a result, the submission file was not generated.",
            "is_bug": "True",
            "parent_index": 17,
            "node_level_analysis": "数据划分: hold-out 20% (train_test_split test_size=0.2, random_state=42)\n特征工程: 数值标准化(StandardScaler) 对10个数值特征\n类别编码: 从 one-hot 还原索引(idxmax → 0-based 索引)用于 Wilderness_Area 与 Soil_Type\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化→TensorDataset, DataLoader batch=4096, shuffle=True（train）, num_workers=4\n模型构建: Embedding + ResNet-MLP，输入 Linear(10+4+16→512)，残差块(512→512×2, 512→256, 256→256)，SE注意力，输出 Linear(256→7)\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, wd=0.01；OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n训练循环: epoch=25，前向→损失→反向→更新→调度",
            "insights_from_parent": [
                "数据预处理：输入格式改为带标记的 '[Q]... [A]...' 串联文本，tokenize 使用通用 truncation=True",
                "特征工程：引入可微 Spearman 近似（torchsort.soft_rank）将预测与标签映射到秩空间直接优化排序指标",
                "模型选择：在 DeBERTa 上加入 AttentionPooling（注意力池化）替代简单 CLS 池化以聚焦重要片段",
                "参数调整：损失由 Pearson 换为 Spearman 近似并加入正则化参数，添加 CosineAnnealingWarmRestarts 学习率调度器",
                "训练策略：每步更新后调用调度器，使用 SpearmanLoss 使训练目标与竞赛指标对齐"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 22,
            "metric": 0.3708,
            "plan": "The error occurs due to an in-place modification of the attention scores tensor\nduring masking. We need to replace the in-place assignment with a masked_fill\noperation that creates a new tensor instead. Additionally, we should verify the\nmodel's forward pass for other potential in-place operations and ensure proper\ngradient flow.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nimport torchsort\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nos.makedirs(\"submission\", exist_ok=True)\n\n# Load data\ntrain_df = pd.read_csv(\"input/train.csv\")\ntest_df = pd.read_csv(\"input/test.csv\")\ntarget_cols = pd.read_csv(\"input/sample_submission.csv\").columns[1:].tolist()\n\n# Prepare text inputs with special tokens\ntrain_df[\"text\"] = (\n    \"[Q] \"\n    + train_df[\"question_title\"]\n    + \" [SEP] \"\n    + train_df[\"question_body\"]\n    + \" [A] \"\n    + train_df[\"answer\"]\n)\ntest_df[\"text\"] = (\n    \"[Q] \"\n    + test_df[\"question_title\"]\n    + \" [SEP] \"\n    + test_df[\"question_body\"]\n    + \" [A] \"\n    + test_df[\"answer\"]\n)\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(\n    train_df[\"text\"], train_df[target_cols], test_size=0.2, random_state=42\n)\n\n# Tokenization\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\nmax_length = 512\n\n\ndef tokenize(texts):\n    return tokenizer.batch_encode_plus(\n        texts,\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\",\n        add_special_tokens=True,\n    )\n\n\ntrain_enc = tokenize(X_train.tolist())\nval_enc = tokenize(X_val.tolist())\ntest_enc = tokenize(test_df[\"text\"].tolist())\n\n\nclass QADataset(Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            \"input_ids\": self.encodings[\"input_ids\"][idx],\n            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n        }\n        if self.labels is not None:\n            item[\"labels\"] = torch.tensor(\n                self.labels.iloc[idx].values, dtype=torch.float\n            )\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n\ntrain_dataset = QADataset(train_enc, y_train)\nval_dataset = QADataset(val_enc, y_val)\ntest_dataset = QADataset(test_enc)\n\n\nclass SpearmanLoss(nn.Module):\n    def __init__(self, regularization=\"l2\", regularization_strength=1.0):\n        super().__init__()\n        self.regularization = regularization\n        self.eps = 1e-7\n        self.regularization_strength = regularization_strength\n\n    def forward(self, preds, targets):\n        preds_rank = torchsort.soft_rank(\n            preds,\n            regularization=self.regularization,\n            regularization_strength=self.regularization_strength,\n        )\n        targets_rank = torchsort.soft_rank(\n            targets,\n            regularization=self.regularization,\n            regularization_strength=self.regularization_strength,\n        )\n\n        preds_rank = preds_rank - preds_rank.mean(dim=0)\n        targets_rank = targets_rank - targets_rank.mean(dim=0)\n\n        cov = (preds_rank * targets_rank).mean(dim=0)\n        preds_std = torch.sqrt((preds_rank**2).mean(dim=0) + self.eps)\n        targets_std = torch.sqrt((targets_rank**2).mean(dim=0) + self.eps)\n\n        spearman = cov / (preds_std * targets_std + self.eps)\n        return 1 - spearman.mean()\n\n\nclass AttentionPooling(nn.Module):\n    def __init__(self, hidden_size):\n        super().__init__()\n        self.attn = nn.Sequential(\n            nn.Linear(hidden_size, 256), nn.Tanh(), nn.Linear(256, 1), nn.Softmax(dim=1)\n        )\n\n    def forward(self, hidden_states, attention_mask):\n        scores = self.attn(hidden_states).squeeze(-1)\n        # Fix: Replace in-place masking with masked_fill\n        scores = scores.masked_fill(~attention_mask.bool(), -1e4)\n        weights = torch.softmax(scores, dim=1)\n        return (hidden_states * weights.unsqueeze(-1)).sum(dim=1)\n\n\nclass CrossEncoderDeBERTa(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.deberta = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n        self.attention_pooling = AttentionPooling(self.deberta.config.hidden_size)\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.deberta.config.hidden_size, 512),\n            nn.GELU(),\n            nn.LayerNorm(512),\n            nn.Dropout(0.2),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.deberta(input_ids, attention_mask=attention_mask)\n        pooled = self.attention_pooling(outputs.last_hidden_state, attention_mask)\n        return torch.sigmoid(self.regressor(self.dropout(pooled)))\n\n\nmodel = CrossEncoderDeBERTa().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n    optimizer, T_0=100, T_mult=1\n)\nloss_fn = SpearmanLoss()\n\nbatch_size = 16\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\nbest_score = 0\nfor epoch in range(5):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(input_ids, attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        total_loss += loss.item()\n\n    # Validation\n    model.eval()\n    preds, truths = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            outputs = model(input_ids, attention_mask).cpu().numpy()\n            preds.append(outputs)\n            truths.append(batch[\"labels\"].numpy())\n\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    spearman_scores = [\n        spearmanr(preds[:, i], truths[:, i]).correlation for i in range(30)\n    ]\n    mean_spearman = np.nanmean(spearman_scores)\n    print(\n        f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Spearman: {mean_spearman:.4f}\"\n    )\n\n    if mean_spearman > best_score:\n        best_score = mean_spearman\n        torch.save(model.state_dict(), \"best_model.pt\")\n\n# Generate submission\nmodel.load_state_dict(torch.load(\"best_model.pt\"))\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        outputs = model(input_ids, attention_mask).cpu().numpy()\n        test_preds.append(outputs)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=target_cols)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nsubmission.to_csv(\"submission/submission.csv\", index=False)\n\nprint(f\"\\nFinal Validation Spearman: {best_score:.4f}\")\n",
            "analysis": "The code successfully trains a model to predict subjective question-answering aspects and generates a submission file in the required format. The model achieves a final validation Spearman correlation of 0.3708, indicating a moderate level of predictive performance. The execution completes without any errors, and the submission file is correctly saved in the specified directory.",
            "is_bug": "False",
            "parent_index": 18,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 标准化(StandardScaler) 对数值特征\n类别编码: one-hot → 索引(argmax)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化+DataLoader(batch=4096, shuffle=True, num_workers=4)\n模型构建: Embedding + ResNet-MLP + SE，输入(10+嵌入)→512，若干残差块，输出7类\n正则化: BatchNorm、Dropout(p=0.3/0.2)、权重衰减=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01) + OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n模型训练: 前向→损失→反向→更新→调度",
            "insights_from_parent": [
                "数据预处理：无变化",
                "特征工程：无变化",
                "模型选择：保留 AttentionPooling，但修复掩码处的原地操作（改为 masked_fill）以确保正确梯度流",
                "参数调整：无超参变动，修复in-place bug以避免运行时错误",
                "训练策略：训练流程保持，修复避免内存/梯度错误以提高训练稳定性"
            ]
        }
    ],
    [
        {
            "demo_id": "google-quest-challenge",
            "node_index": 1,
            "metric": null,
            "plan": "To tackle this problem, we'll use a pre-trained BERT model to capture semantic\nrelationships between questions and answers, followed by a regression head to\npredict all 30 targets simultaneously. We'll concatenate the question title,\nbody, and answer text as input, then fine-tune the model using MSE loss. For\nvalidation, we'll compute the mean Spearman correlation across all targets using\na 20% holdout set from the training data. This approach leverages transformer\ncapabilities for text understanding while maintaining efficient training on the\navailable GPU.",
            "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertModel, AdamW\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom scipy.stats import spearmanr\nfrom tqdm import tqdm\n\n\nclass QADataset(Dataset):\n    def __init__(self, texts, targets, tokenizer, max_len):\n        self.texts = texts\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_attention_mask=True,\n        )\n        return {\n            \"input_ids\": torch.tensor(inputs[\"input_ids\"], dtype=torch.long),\n            \"attention_mask\": torch.tensor(inputs[\"attention_mask\"], dtype=torch.long),\n            \"targets\": torch.tensor(self.targets[idx], dtype=torch.float),\n        }\n\n\nclass BertMultiRegressor(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.dropout = nn.Dropout(0.1)\n        self.regressor = nn.Linear(self.bert.config.hidden_size, 30)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled = self.dropout(outputs.pooler_output)\n        return torch.sigmoid(self.regressor(pooled))\n\n\ndef compute_metric(y_true, y_pred):\n    corrs = []\n    for i in range(y_true.shape[1]):\n        corr, _ = spearmanr(y_true[:, i], y_pred[:, i])\n        corrs.append(corr)\n    return np.nanmean(corrs)\n\n\ndef main():\n    # Load and preprocess data\n    train_df = pd.read_csv(\"input/train.csv\")\n    test_df = pd.read_csv(\"input/test.csv\")\n\n    # Combine text fields\n    train_texts = (\n        train_df[\"question_title\"]\n        + \" \"\n        + train_df[\"question_body\"]\n        + \" \"\n        + train_df[\"answer\"]\n    )\n    test_texts = (\n        test_df[\"question_title\"]\n        + \" \"\n        + test_df[\"question_body\"]\n        + \" \"\n        + test_df[\"answer\"]\n    )\n\n    # Extract targets\n    target_cols = train_df.columns[-30:].tolist()\n    targets = train_df[target_cols].values\n\n    # Train-validation split\n    X_train, X_val, y_train, y_val = train_test_split(\n        train_texts, targets, test_size=0.2, random_state=42\n    )\n\n    # Initialize tokenizer and model\n    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n    model = BertMultiRegressor().cuda()\n    optimizer = AdamW(model.parameters(), lr=2e-5)\n    criterion = nn.MSELoss()\n\n    # Create dataloaders\n    train_dataset = QADataset(X_train.tolist(), y_train, tokenizer, 512)\n    val_dataset = QADataset(X_val.tolist(), y_val, tokenizer, 512)\n\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n    val_loader = DataLoader(val_dataset, batch_size=32, num_workers=4)\n\n    # Training loop\n    best_score = -1\n    for epoch in range(3):\n        model.train()\n        for batch in tqdm(train_loader):\n            optimizer.zero_grad()\n            inputs = {k: v.cuda() for k, v in batch.items() if k != \"targets\"}\n            targets = batch[\"targets\"].cuda()\n\n            outputs = model(**inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n        # Validation\n        model.eval()\n        val_preds, val_true = [], []\n        with torch.no_grad():\n            for batch in val_loader:\n                inputs = {k: v.cuda() for k, v in batch.items() if k != \"targets\"}\n                outputs = model(**inputs).cpu().numpy()\n                val_preds.append(outputs)\n                val_true.append(batch[\"targets\"].numpy())\n\n        val_preds = np.concatenate(val_preds)\n        val_true = np.concatenate(val_true)\n        score = compute_metric(val_true, val_preds)\n        print(f\"Epoch {epoch+1} Val Score: {score:.4f}\")\n\n        if score > best_score:\n            best_score = score\n            torch.save(model.state_dict(), \"best_model.pth\")\n\n    # Generate predictions\n    test_dataset = QADataset(\n        test_texts.tolist(), np.zeros((len(test_texts), 30)), tokenizer, 512\n    )\n    test_loader = DataLoader(test_dataset, batch_size=32, num_workers=4)\n\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for batch in tqdm(test_loader):\n            inputs = {k: v.cuda() for k, v in batch.items() if k != \"targets\"}\n            outputs = model(**inputs).cpu().numpy()\n            predictions.append(outputs)\n\n    # Save submission\n    submission = pd.DataFrame(np.concatenate(predictions), columns=target_cols)\n    submission.insert(0, \"qa_id\", test_df[\"qa_id\"])\n    submission.to_csv(\"submission/submission.csv\", index=False)\n    print(f\"Best Validation Score: {best_score:.4f}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
            "analysis": "The code executed successfully, producing a 'submission.csv' file with predictions for the test data. The validation process was conducted over 3 epochs, and the best validation score achieved was 0.3245, indicating the mean column-wise Spearman's correlation coefficient. The metric for this competition should be maximized, as a higher correlation indicates better performance.",
            "is_bug": "True",
            "parent_index": 0,
            "node_level_analysis": "数据划分: hold-out 80/20，random_state=42\n特征工程: 数值标准化(StandardScaler)对10个数值特征\n类别编码: one-hot→索引 via idxmax（Wilderness 4类→0-3，Soil 40类→0-39）\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化+DataLoader，batch=4096，train shuffle=True，num_workers=4\n模型构建: Embedding + ResNet-MLP 带SE；输入 Linear(10+4+16→512)，残差块序列[512→512,512→512,512→256,256→256]，输出 Linear(256→7)\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、weight_decay=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01)，OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n模型训练: 前向→损失→反向→更新→调度，epoch=25\n后处理/阈值: 预测 +1 映射回 1-7 类别",
            "insights_from_parent": [
                "根节点，无需分析"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 3,
            "metric": null,
            "plan": "The previous code may fail to create the submission directory if it doesn't\nexist. The fix involves creating the directory before saving and adding proper\ntext preprocessing for question/answer separation. We'll also add gradient\nclipping and increase model capacity slightly.",
            "code": "import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertModel, AdamW\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom scipy.stats import spearmanr\nfrom tqdm import tqdm\n\nos.makedirs(\"submission\", exist_ok=True)\n\n\nclass QADataset(Dataset):\n    def __init__(self, questions, answers, targets, tokenizer, max_len):\n        self.questions = questions\n        self.answers = answers\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        question = str(self.questions[idx])\n        answer = str(self.answers[idx])\n\n        # Tokenize question and answer separately\n        inputs = self.tokenizer(\n            text=question,\n            text_pair=answer,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n\n        if self.targets is not None:\n            return {\n                \"input_ids\": inputs[\"input_ids\"].squeeze(),\n                \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n                \"targets\": torch.tensor(self.targets[idx], dtype=torch.float),\n            }\n        return {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n        }\n\n\nclass BertMultiRegressor(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.bert.config.hidden_size, 512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled = self.dropout(outputs.last_hidden_state[:, 0, :])\n        return torch.sigmoid(self.regressor(pooled))\n\n\ndef compute_metric(y_true, y_pred):\n    corrs = []\n    for i in range(y_true.shape[1]):\n        corr, _ = spearmanr(y_true[:, i], y_pred[:, i])\n        corrs.append(corr)\n    return np.nanmean(corrs)\n\n\ndef main():\n    train_df = pd.read_csv(\"input/train.csv\")\n    test_df = pd.read_csv(\"input/test.csv\")\n\n    target_cols = train_df.columns[-30:].tolist()\n    targets = train_df[target_cols].values\n\n    X_train, X_val = train_test_split(train_df, test_size=0.2, random_state=42)\n\n    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n    model = BertMultiRegressor().cuda()\n    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\n    criterion = nn.MSELoss()\n\n    train_dataset = QADataset(\n        X_train[\"question_body\"],\n        X_train[\"answer\"],\n        X_train[target_cols].values,\n        tokenizer,\n        512,\n    )\n    val_dataset = QADataset(\n        X_val[\"question_body\"],\n        X_val[\"answer\"],\n        X_val[target_cols].values,\n        tokenizer,\n        512,\n    )\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True\n    )\n    val_loader = DataLoader(val_dataset, batch_size=32, num_workers=4, pin_memory=True)\n\n    best_score = -1\n    for epoch in range(5):\n        model.train()\n        total_loss = 0\n        for batch in tqdm(train_loader):\n            optimizer.zero_grad()\n            inputs = {k: v.cuda() for k, v in batch.items() if k != \"targets\"}\n            targets = batch[\"targets\"].cuda()\n\n            outputs = model(**inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            total_loss += loss.item()\n\n        model.eval()\n        val_preds, val_true = [], []\n        with torch.no_grad():\n            for batch in val_loader:\n                inputs = {k: v.cuda() for k, v in batch.items() if k != \"targets\"}\n                outputs = model(**inputs).cpu().numpy()\n                val_preds.append(outputs)\n                val_true.append(batch[\"targets\"].numpy())\n\n        val_preds = np.concatenate(val_preds)\n        val_true = np.concatenate(val_true)\n        score = compute_metric(val_true, val_preds)\n        print(\n            f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Score: {score:.4f}\"\n        )\n\n        if score > best_score:\n            best_score = score\n            torch.save(model.state_dict(), \"best_model.pth\")\n\n    # Generate predictions\n    test_dataset = QADataset(\n        test_df[\"question_body\"], test_df[\"answer\"], None, tokenizer, 512\n    )\n    test_loader = DataLoader(test_dataset, batch_size=32, num_workers=4)\n\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for batch in tqdm(test_loader):\n            inputs = {k: v.cuda() for k, v in batch.items()}\n            outputs = model(**inputs).cpu().numpy()\n            predictions.append(outputs)\n\n    submission = pd.DataFrame(np.concatenate(predictions), columns=target_cols)\n    submission.insert(0, \"qa_id\", test_df[\"qa_id\"])\n    submission.to_csv(\"submission/submission.csv\", index=False)\n    print(f\"\\nBest Validation Score: {best_score:.4f}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
            "analysis": "The code successfully trains a BERT-based model to predict the target variables for the question-answer pairs. The model is evaluated using the mean column-wise Spearman's correlation coefficient, achieving a validation score of 0.4578. The predictions are saved in a 'submission.csv' file in the specified directory, indicating a successful execution without any bugs.",
            "is_bug": "True",
            "parent_index": 1,
            "node_level_analysis": "数据划分: hold-out 80/20，random_state=42\n特征工程: one-hot→类别索引(Wilderness, Soil)，数值特征StandardScaler标准化(10个数值)，目标Cover_Type 1-7→0-6\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化+DataLoader(batch=4096, shuffle=True(train), val_batch=4096, num_workers=4)\n模型构建: EmbeddingResNet，输入10+4+16→512，残差块堆叠(512→512,512→512,512→256,256→256)，输出256→7，激活GELU，SE注意力\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、L2权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01)，OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n模型训练: 前向→损失→反向→更新→调度，epoch=25",
            "insights_from_parent": [
                "数据预处理：将 question 与 answer 分开 tokenization（text_pair）",
                "特征工程：保留问答对结构，不再把三段文本简单拼接为单一字符串",
                "模型选择：回归头增加隐藏层（BERT hidden -> 512 -> 30），改用 last_hidden_state 第0位池化",
                "参数调整：增大 dropout（0.1→0.2）、引入 weight_decay=1e-4、将 epoch 提升到5",
                "训练策略：加入梯度裁剪(nn.utils.clip_grad_norm_)，使用 pin_memory 并改善数据加载"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 6,
            "metric": null,
            "plan": "The previous code failed to include the `question_title` in the input features,\nwhich is crucial for predicting question-related targets. The fix concatenates\n`question_title` and `question_body` for question context, ensuring the model\ncaptures all relevant information. Additionally, the code now properly handles\npotential NaN values in text fields and optimizes training with mixed-precision\nand gradient accumulation for stability.",
            "code": "import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertModel, AdamW\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom scipy.stats import spearmanr\nfrom tqdm import tqdm\n\nos.makedirs(\"submission\", exist_ok=True)\n\n\nclass QADataset(Dataset):\n    def __init__(self, questions, answers, targets, tokenizer, max_len):\n        self.questions = questions\n        self.answers = answers\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        question = str(self.questions[idx])\n        answer = str(self.answers[idx])\n\n        inputs = self.tokenizer(\n            text=question,\n            text_pair=answer,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n\n        if self.targets is not None:\n            return {\n                \"input_ids\": inputs[\"input_ids\"].squeeze(),\n                \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n                \"targets\": torch.tensor(self.targets[idx], dtype=torch.float),\n            }\n        return {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n        }\n\n\nclass BertMultiRegressor(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.bert.config.hidden_size, 512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled = self.dropout(outputs.last_hidden_state[:, 0, :])\n        return torch.sigmoid(self.regressor(pooled))\n\n\ndef compute_metric(y_true, y_pred):\n    corrs = []\n    for i in range(y_true.shape[1]):\n        corr, _ = spearmanr(y_true[:, i], y_pred[:, i])\n        corrs.append(corr)\n    return np.nanmean(corrs)\n\n\ndef main():\n    train_df = pd.read_csv(\"input/train.csv\")\n    test_df = pd.read_csv(\"input/test.csv\")\n\n    # Create full question context\n    train_df[\"full_question\"] = (\n        train_df[\"question_title\"].fillna(\"\")\n        + \" \"\n        + train_df[\"question_body\"].fillna(\"\")\n    )\n    test_df[\"full_question\"] = (\n        test_df[\"question_title\"].fillna(\"\") + \" \" + test_df[\"question_body\"].fillna(\"\")\n    )\n\n    target_cols = train_df.columns[-30:].tolist()\n    targets = train_df[target_cols].values\n\n    X_train, X_val = train_test_split(train_df, test_size=0.2, random_state=42)\n\n    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n    model = BertMultiRegressor().cuda()\n    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\n    criterion = nn.MSELoss()\n    scaler = GradScaler()\n\n    train_dataset = QADataset(\n        X_train[\"full_question\"],\n        X_train[\"answer\"].fillna(\"\"),\n        X_train[target_cols].values,\n        tokenizer,\n        512,\n    )\n    val_dataset = QADataset(\n        X_val[\"full_question\"],\n        X_val[\"answer\"].fillna(\"\"),\n        X_val[target_cols].values,\n        tokenizer,\n        512,\n    )\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True\n    )\n    val_loader = DataLoader(val_dataset, batch_size=32, num_workers=4, pin_memory=True)\n\n    best_score = -1\n    for epoch in range(3):\n        model.train()\n        total_loss = 0\n        optimizer.zero_grad()\n\n        for step, batch in enumerate(tqdm(train_loader)):\n            inputs = {k: v.cuda() for k, v in batch.items() if k != \"targets\"}\n            targets = batch[\"targets\"].cuda()\n\n            with autocast():\n                outputs = model(**inputs)\n                loss = criterion(outputs, targets) / 4  # Gradient accumulation\n\n            scaler.scale(loss).backward()\n\n            if (step + 1) % 4 == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n\n            total_loss += loss.item() * 4  # Multiply back gradient accumulation\n\n        model.eval()\n        val_preds, val_true = [], []\n        with torch.no_grad():\n            for batch in val_loader:\n                inputs = {k: v.cuda() for k, v in batch.items() if k != \"targets\"}\n                outputs = model(**inputs).cpu().numpy()\n                val_preds.append(outputs)\n                val_true.append(batch[\"targets\"].numpy())\n\n        val_preds = np.concatenate(val_preds)\n        val_true = np.concatenate(val_true)\n        score = compute_metric(val_true, val_preds)\n        print(\n            f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Score: {score:.4f}\"\n        )\n\n        if score > best_score:\n            best_score = score\n            torch.save(model.state_dict(), \"best_model.pth\")\n\n    # Generate predictions\n    test_dataset = QADataset(\n        test_df[\"full_question\"], test_df[\"answer\"].fillna(\"\"), None, tokenizer, 512\n    )\n    test_loader = DataLoader(test_dataset, batch_size=32, num_workers=4)\n\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for batch in tqdm(test_loader):\n            inputs = {k: v.cuda() for k, v in batch.items()}\n            outputs = model(**inputs).cpu().numpy()\n            predictions.append(outputs)\n\n    submission = pd.DataFrame(np.concatenate(predictions), columns=target_cols)\n    submission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\n    submission.to_csv(\"submission/submission.csv\", index=False)\n    print(f\"\\nBest Validation Score: {best_score:.4f}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
            "analysis": "The training script successfully executed, producing a 'submission.csv' file with predictions for the test data. The model achieved a best validation score of 0.7321, which indicates the mean column-wise Spearman's correlation coefficient. The metric used in this competition is to be maximized, so a higher value is better.",
            "is_bug": "True",
            "parent_index": 3,
            "node_level_analysis": "数据划分: train_test_split test_size=0.2, random_state=42\n特征工程: 标准化（StandardScaler）对10个数值特征\n类别编码: one-hot→index（Wilderness 4类、Soil 40类）\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化+DataLoader（batch=4096, shuffle=True, num_workers=4, val_batch=4096）\n模型构建: Embedding + ResNet-MLP（输入10+4+16→512，blocks: 512→512, 512→512, 512→256, 256→256，输出256→7），SE通道缩减=16，激活GELU\n正则化: Dropout(p=0.3/0.2)、BatchNorm1d、权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, wd=0.01；OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n模型训练: 前向→损失→反向→更新→调度, epoch=25",
            "insights_from_parent": [
                "数据预处理：拼接 question_title 与 question_body 为 full_question，并对缺失值 fillna('')",
                "特征工程：继续使用 text_pair (full_question, answer)，max_length=512，padding/truncation 保持不变",
                "模型选择：模型结构保持 BERT + 512 隐藏回归头，无结构性变化",
                "参数调整：引入混合精度(autocast + GradScaler)，保留 weight_decay=1e-4，epochs 调整为3",
                "训练策略：加入梯度累积（steps=4）以稳定训练并节省显存，按步更新优化器"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 9,
            "metric": null,
            "plan": "The previous code incorrectly used the training data's column order for target\nlabels, which may mismatch the submission format. The fix reads the correct\ntarget column order from sample_submission.csv and ensures predictions align\nwith required formatting. Additionally, the validation set creation now uses\nstratified sampling by 'category' to prevent data leakage.",
            "code": "import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertModel, AdamW\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom scipy.stats import spearmanr\nfrom tqdm import tqdm\n\nos.makedirs(\"submission\", exist_ok=True)\n\n# Get correct target column order from sample submission\nsample_sub = pd.read_csv(\"input/sample_submission.csv\")\nTARGET_COLS = sample_sub.columns[1:].tolist()  # 30 target columns in correct order\n\n\nclass QADataset(Dataset):\n    def __init__(self, questions, answers, targets, tokenizer, max_len):\n        self.questions = questions\n        self.answers = answers\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        question = str(self.questions[idx])\n        answer = str(self.answers[idx])\n\n        inputs = self.tokenizer(\n            text=question,\n            text_pair=answer,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n\n        if self.targets is not None:\n            return {\n                \"input_ids\": inputs[\"input_ids\"].squeeze(),\n                \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n                \"targets\": torch.tensor(self.targets[idx], dtype=torch.float),\n            }\n        return {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n        }\n\n\nclass BertMultiRegressor(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.dropout = nn.Dropout(0.2)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.bert.config.hidden_size, 512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled = self.dropout(outputs.last_hidden_state[:, 0, :])\n        return torch.sigmoid(self.regressor(pooled))\n\n\ndef compute_metric(y_true, y_pred):\n    corrs = []\n    for i in range(y_true.shape[1]):\n        corr, _ = spearmanr(y_true[:, i], y_pred[:, i])\n        corrs.append(corr)\n    return np.nanmean(corrs)\n\n\ndef main():\n    train_df = pd.read_csv(\"input/train.csv\")\n    test_df = pd.read_csv(\"input/test.csv\")\n\n    # Create full question context\n    train_df[\"full_question\"] = (\n        train_df[\"question_title\"].fillna(\"\")\n        + \" \"\n        + train_df[\"question_body\"].fillna(\"\")\n    )\n    test_df[\"full_question\"] = (\n        test_df[\"question_title\"].fillna(\"\") + \" \" + test_df[\"question_body\"].fillna(\"\")\n    )\n\n    # Use correct target column order from sample submission\n    targets = train_df[TARGET_COLS].values\n\n    # Stratified split by category to prevent leakage\n    X_train, X_val = train_test_split(\n        train_df, test_size=0.2, random_state=42, stratify=train_df[\"category\"]\n    )\n\n    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n    model = BertMultiRegressor().cuda()\n    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\n    criterion = nn.MSELoss()\n    scaler = GradScaler()\n\n    train_dataset = QADataset(\n        X_train[\"full_question\"],\n        X_train[\"answer\"].fillna(\"\"),\n        X_train[TARGET_COLS].values,\n        tokenizer,\n        512,\n    )\n    val_dataset = QADataset(\n        X_val[\"full_question\"],\n        X_val[\"answer\"].fillna(\"\"),\n        X_val[TARGET_COLS].values,\n        tokenizer,\n        512,\n    )\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True\n    )\n    val_loader = DataLoader(val_dataset, batch_size=32, num_workers=4, pin_memory=True)\n\n    best_score = -1\n    for epoch in range(3):\n        model.train()\n        total_loss = 0\n        optimizer.zero_grad()\n\n        for step, batch in enumerate(tqdm(train_loader)):\n            inputs = {k: v.cuda() for k, v in batch.items() if k != \"targets\"}\n            targets = batch[\"targets\"].cuda()\n\n            with autocast():\n                outputs = model(**inputs)\n                loss = criterion(outputs, targets) / 4  # Gradient accumulation\n\n            scaler.scale(loss).backward()\n\n            if (step + 1) % 4 == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n\n            total_loss += loss.item() * 4  # Multiply back gradient accumulation\n\n        # Validation\n        model.eval()\n        val_preds, val_true = [], []\n        with torch.no_grad():\n            for batch in val_loader:\n                inputs = {k: v.cuda() for k, v in batch.items() if k != \"targets\"}\n                outputs = model(**inputs).cpu().numpy()\n                val_preds.append(outputs)\n                val_true.append(batch[\"targets\"].numpy())\n\n        val_preds = np.concatenate(val_preds)\n        val_true = np.concatenate(val_true)\n        score = compute_metric(val_true, val_preds)\n        print(\n            f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | Val Score: {score:.4f}\"\n        )\n\n        if score > best_score:\n            best_score = score\n            torch.save(model.state_dict(), \"best_model.pth\")\n\n    # Generate submission\n    test_dataset = QADataset(\n        test_df[\"full_question\"], test_df[\"answer\"].fillna(\"\"), None, tokenizer, 512\n    )\n    test_loader = DataLoader(test_dataset, batch_size=32, num_workers=4)\n\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for batch in tqdm(test_loader):\n            inputs = {k: v.cuda() for k, v in batch.items()}\n            outputs = model(**inputs).cpu().numpy()\n            predictions.append(outputs)\n\n    submission = pd.DataFrame(np.concatenate(predictions), columns=TARGET_COLS)\n    submission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\n    submission.to_csv(\"submission/submission.csv\", index=False)\n    print(f\"\\nBest Validation Score: {best_score:.4f}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
            "analysis": "The code successfully trains a BERT-based model to predict the subjective aspects of question-answer pairs, achieving a validation score of 0.1824 in terms of mean column-wise Spearman's correlation coefficient. The predictions are saved in the required 'submission.csv' format, indicating that the submission process is correctly implemented. There are no evident bugs in the execution output, and the metric should be maximized for better performance.",
            "is_bug": "True",
            "parent_index": 6,
            "node_level_analysis": "缺失值处理: question_title/question_body/answer fillna(\"\")  \n特征工程: 文本拼接 full_question = title + \" \" + body，tokenizer=BertTokenizer('bert-base-uncased')，text_pair=answer，max_length=512，padding=\"max_length\"，truncation  \n数据划分: Stratified hold-out test_size=0.2，random_state=42，stratify=category  \n数据管道: DataLoader batch_size=16(train) / 32(val,test)，shuffle=True(train)，num_workers=4，pin_memory=True(train,val)  \n模型构建: Transformer(BERT 'bert-base-uncased')，CLS 池化 pooled = last_hidden_state[:,0,:]，回归头 Linear(hidden_size→512)→ReLU→Dropout(p=0.1)→Linear(512→30)，输出 sigmoid，池化 Dropout(p=0.2)  \n正则化: Dropout(p=0.2)、Dropout(p=0.1)，权重衰减 wd=1e-4  \n损失函数: MSELoss  \n优化与训练: AdamW lr=2e-5, wd=1e-4，混合精度 autocast + GradScaler，梯度累积 steps=4（loss/=4，4步更新），epochs=3  \n评估/度量: 每列 Spearman 相关(cohort-wise spearmanr)，取均值作为验证分数  \n预测与提交: 从 sample_submission.csv 读取 TARGET_COLS 保持列序，生成 submission.csv，包含 qa_id 和按 TARGET_COLS 排序的预测结果",
            "insights_from_parent": [
                "数据预处理：从 sample_submission 读取正确 TARGET_COLS，保证提交列顺序一致",
                "特征工程：文本处理与 tokenizer 使用方式保持不变，无新增特征工程",
                "模型选择：模型架构未改变（继续使用 BERT + 512 回归头）",
                "参数调整：超参数无显著调整，训练相关配置保持与父节点一致",
                "训练策略：在划分验证集时使用按 'category' 的分层采样(stratify)，降低数据泄漏风险"
            ]
        }
    ],
    [
        {
            "demo_id": "google-quest-challenge",
            "node_index": 13,
            "metric": null,
            "plan": "To address the multi-target regression task, we'll use a BERT-based model that\nseparately encodes question and answer texts, incorporates categorical features\n(category and host), and combines them for prediction. This approach leverages\nsemantic understanding from BERT while capturing platform-specific patterns\nthrough categorical embeddings. We'll validate using a 20% split and compute\nmean Spearman correlation across all targets.",
            "code": "import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport os\n\n# Load data\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntest_df = pd.read_csv(\"./input/test.csv\")\n\n# Preprocess categorical features\nfor col in [\"category\", \"host\"]:\n    train_values = train_df[col].unique()\n    train_df[f\"{col}_idx\"] = train_df[col].astype(\"category\").cat.codes + 1\n    test_df[f\"{col}_idx\"] = (\n        test_df[col]\n        .apply(lambda x: x if x in train_values else \"unknown\")\n        .astype(\"category\")\n        .cat.codes\n        + 1\n    )\n\n# Dataset parameters\nTARGETS = train_df.columns[-30:].tolist()\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmax_len = 384\n\n\n# Custom Dataset\nclass QAPairs(Dataset):\n    def __init__(self, df, is_test=False):\n        self.df = df\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        question = f\"{row['question_title']} [SEP] {row['question_body']}\"\n        question_enc = tokenizer(\n            question,\n            padding=\"max_length\",\n            max_length=max_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        answer_enc = tokenizer(\n            row[\"answer\"],\n            padding=\"max_length\",\n            max_length=max_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n\n        item = {\n            \"q_input_ids\": question_enc[\"input_ids\"].squeeze(),\n            \"q_attn_mask\": question_enc[\"attention_mask\"].squeeze(),\n            \"a_input_ids\": answer_enc[\"input_ids\"].squeeze(),\n            \"a_attn_mask\": answer_enc[\"attention_mask\"].squeeze(),\n            \"category\": torch.tensor(row[\"category_idx\"], dtype=torch.long),\n            \"host\": torch.tensor(row[\"host_idx\"], dtype=torch.long),\n        }\n        if not self.is_test:\n            item[\"targets\"] = torch.tensor(row[TARGETS].values, dtype=torch.float)\n        return item\n\n\n# Model architecture\nclass DualBERT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n        self.cat_emb = nn.Embedding(100, 16)\n        self.host_emb = nn.Embedding(100, 16)\n        self.head = nn.Sequential(\n            nn.Linear(768 * 2 + 32, 512), nn.SiLU(), nn.Dropout(0.2), nn.Linear(512, 30)\n        )\n\n    def forward(self, q_ids, q_mask, a_ids, a_mask, cat, host):\n        q_out = self.bert(q_ids, q_mask).last_hidden_state[:, 0]\n        a_out = self.bert(a_ids, a_mask).last_hidden_state[:, 0]\n        cat_emb = self.cat_emb(cat)\n        host_emb = self.host_emb(host)\n        combined = torch.cat([q_out, a_out, cat_emb, host_emb], 1)\n        return torch.sigmoid(self.head(combined))\n\n\n# Data preparation\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntrain_ds = QAPairs(train)\nval_ds = QAPairs(val)\ntest_ds = QAPairs(test_df, is_test=True)\n\nbatch_size = 16\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=4)\n\n# Training setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = DualBERT().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\ncriterion = nn.MSELoss()\n\n# Training loop\nbest_score = 0\nfor epoch in range(3):\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"targets\"]}\n        preds = model(**inputs)\n        loss = criterion(preds, batch[\"targets\"].to(device))\n        loss.backward()\n        optimizer.step()\n\n    # Validation\n    model.eval()\n    all_preds, all_targets = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"targets\"]}\n            preds = model(**inputs).cpu().numpy()\n            all_preds.append(preds)\n            all_targets.append(batch[\"targets\"].numpy())\n\n    # Calculate metric\n    val_preds = np.concatenate(all_preds)\n    val_targets = np.concatenate(all_targets)\n    spearman_scores = []\n    for i in range(30):\n        spearman_scores.append(\n            spearmanr(val_preds[:, i], val_targets[:, i]).correlation\n        )\n    mean_score = np.nanmean(spearman_scores)\n    print(f\"Epoch {epoch+1} Validation Score: {mean_score:.4f}\")\n    best_score = max(best_score, mean_score)\n\n# Generate predictions\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs = {k: v.to(device) for k, v in batch.items()}\n        preds = model(**inputs).cpu().numpy()\n        test_preds.append(preds)\n\n# Create submission\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=TARGETS)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nos.makedirs(\"./submission\", exist_ok=True)\nsubmission.to_csv(\"./submission/submission.csv\", index=False)\nprint(f\"Final Validation Score: {best_score:.4f}\")\n",
            "analysis": "The code execution failed due to a TypeError in the DataLoader worker process. The error was caused by an attempt to convert an np.ndarray of type numpy.object_ to a torch tensor, which is not supported. As a result, the submission.csv file was not produced successfully.",
            "is_bug": "True",
            "parent_index": 0,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 标准化(StandardScaler) 对10个数值特征、目标变换 Cover_Type→0-6\n类别编码: one-hot→整数索引(Wilderness、Soil)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化→TensorDataset, DataLoader batch=4096, shuffle(train), num_workers=4\n模型构建: Embedding + MLP残差块, 输入10+4+16→512, blocks: 512→512 Dropout(p=0.3)×2, 512→256 Dropout(p=0.2)×2, SE注意力, 输出线性→7\n正则化: BatchNorm、Dropout(p=0.3)、Dropout(p=0.2)、L2权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, wd=0.01; OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3；训练循环: 前向→损失→反向→更新→调度, epoch=25",
            "insights_from_parent": [
                "使用双BERT并加类别嵌入"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 15,
            "metric": null,
            "plan": "The error occurs because the target columns are read as objects instead of\nfloats, causing conversion failure. To fix this: 1) Extract target columns\nbefore adding new features to avoid incorrect column indexing. 2) Convert target\ncolumns to float explicitly. 3) Ensure data types are correct when creating\ntensors.",
            "code": "import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport os\n\n# Load data and define targets first\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntest_df = pd.read_csv(\"./input/test.csv\")\nTARGETS = train_df.columns[-30:].tolist()  # Extract before modifying columns\n\n# Convert targets to float\ntrain_df[TARGETS] = train_df[TARGETS].astype(float)\n\n# Preprocess categorical features\nfor col in [\"category\", \"host\"]:\n    train_values = train_df[col].unique()\n    train_df[f\"{col}_idx\"] = train_df[col].astype(\"category\").cat.codes + 1\n    test_df[f\"{col}_idx\"] = (\n        test_df[col]\n        .apply(lambda x: x if x in train_values else \"unknown\")\n        .astype(\"category\")\n        .cat.codes\n        + 1\n    )\n\n# Dataset parameters\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmax_len = 384\n\n\nclass QAPairs(Dataset):\n    def __init__(self, df, is_test=False):\n        self.df = df\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        question = f\"{row['question_title']} [SEP] {row['question_body']}\"\n        question_enc = tokenizer(\n            question,\n            padding=\"max_length\",\n            max_length=max_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        answer_enc = tokenizer(\n            row[\"answer\"],\n            padding=\"max_length\",\n            max_length=max_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n\n        item = {\n            \"q_input_ids\": question_enc[\"input_ids\"].squeeze(),\n            \"q_attn_mask\": question_enc[\"attention_mask\"].squeeze(),\n            \"a_input_ids\": answer_enc[\"input_ids\"].squeeze(),\n            \"a_attn_mask\": answer_enc[\"attention_mask\"].squeeze(),\n            \"category\": torch.tensor(row[\"category_idx\"], dtype=torch.long),\n            \"host\": torch.tensor(row[\"host_idx\"], dtype=torch.long),\n        }\n        if not self.is_test:\n            # Use pre-converted float values\n            targets = torch.tensor(\n                row[TARGETS].values.astype(np.float32), dtype=torch.float\n            )\n            item[\"targets\"] = targets\n        return item\n\n\nclass DualBERT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n        self.cat_emb = nn.Embedding(100, 16)\n        self.host_emb = nn.Embedding(100, 16)\n        self.head = nn.Sequential(\n            nn.Linear(768 * 2 + 32, 512), nn.SiLU(), nn.Dropout(0.2), nn.Linear(512, 30)\n        )\n\n    def forward(self, q_ids, q_mask, a_ids, a_mask, cat, host):\n        q_out = self.bert(q_ids, q_mask).last_hidden_state[:, 0]\n        a_out = self.bert(a_ids, a_mask).last_hidden_state[:, 0]\n        cat_emb = self.cat_emb(cat)\n        host_emb = self.host_emb(host)\n        combined = torch.cat([q_out, a_out, cat_emb, host_emb], 1)\n        return torch.sigmoid(self.head(combined))\n\n\n# Data preparation\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntrain_ds = QAPairs(train)\nval_ds = QAPairs(val)\ntest_ds = QAPairs(test_df, is_test=True)\n\nbatch_size = 16\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=4)\n\n# Training setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = DualBERT().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\ncriterion = nn.MSELoss()\n\nbest_score = 0\nfor epoch in range(3):\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        inputs = {k: v.to(device) for k, v in batch.items() if k != \"targets\"}\n        preds = model(**inputs)\n        loss = criterion(preds, batch[\"targets\"].to(device))\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    all_preds, all_targets = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            inputs = {k: v.to(device) for k, v in batch.items() if k != \"targets\"}\n            preds = model(**inputs).cpu().numpy()\n            all_preds.append(preds)\n            all_targets.append(batch[\"targets\"].numpy())\n\n    val_preds = np.concatenate(all_preds)\n    val_targets = np.concatenate(all_targets)\n    spearman_scores = []\n    for i in range(30):\n        spearman_scores.append(\n            spearmanr(val_preds[:, i], val_targets[:, i]).correlation\n        )\n    mean_score = np.nanmean(spearman_scores)\n    print(f\"Epoch {epoch+1} Validation Score: {mean_score:.4f}\")\n    best_score = max(best_score, mean_score)\n\n# Generate and save predictions\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs = {k: v.to(device) for k, v in batch.items()}\n        preds = model(**inputs).cpu().numpy()\n        test_preds.append(preds)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=TARGETS)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nos.makedirs(\"./submission\", exist_ok=True)\nsubmission.to_csv(\"./submission/submission.csv\", index=False)\nprint(f\"Final Validation Score: {best_score:.4f}\")\n",
            "analysis": "The code execution failed due to a TypeError, indicating that the DualBERT model's forward method received an unexpected keyword argument 'q_input_ids'. This suggests a bug in the code, as the model was not able to process the inputs as intended. Additionally, the submission.csv file was not produced, which prevents evaluation of the model's predictions.",
            "is_bug": "True",
            "parent_index": 13,
            "node_level_analysis": "数据划分: hold-out 80/20，train_test_split test_size=0.2，random_state=42\n特征工程: 数值特征标准化 StandardScaler（10 个数值列）\n类别编码: 从 one-hot 恢复索引 via idxmax + 提取数字，Wilderness/Soil 转为 0-based 索引\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化(TensorDataset)、DataLoader batch=4096、shuffle=True、num_workers=4\n模型构建: EmbeddingResNet（embedding + MLP + 残差块），输入 Linear(10+4+16→512)，残差块序列 512→512, 512→512, 512→256, 256→256，输出 Linear(256→7)，包含 SE 模块\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, weight_decay=0.01；OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n训练循环: epoch=25，前向→损失→反向→更新→调度，保存最佳模型(\"./working/best_model.pt\")",
            "insights_from_parent": [
                "数据预处理：提前提取目标列并显式转为浮点，修复dtype错误",
                "特征工程：保持原有文本与类别编码方案，无新增变换",
                "模型选择：保留DualBERT架构与类别嵌入设计",
                "参数调整：未修改模型超参数或嵌入维度",
                "训练策略：在Dataset中强制使用float32 targets，避免张量创建失败"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 19,
            "metric": 0.3536,
            "plan": "The error occurs because the model's forward method parameter names (q_ids,\nq_mask) don't match the dataset's output keys (q_input_ids, q_attn_mask). We\nneed to align these names by modifying the dataset's dictionary keys to match\nthe model's expected inputs. Also ensure categorical features are properly\nembedded and the submission file is saved.",
            "code": "import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport os\n\n# Load data and define targets\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntest_df = pd.read_csv(\"./input/test.csv\")\nTARGETS = train_df.columns[-30:].tolist()\ntrain_df[TARGETS] = train_df[TARGETS].astype(float)\n\n# Preprocess categorical features\nfor col in [\"category\", \"host\"]:\n    train_values = train_df[col].unique()\n    train_df[f\"{col}_idx\"] = train_df[col].astype(\"category\").cat.codes + 1\n    test_df[f\"{col}_idx\"] = (\n        test_df[col]\n        .apply(lambda x: x if x in train_values else \"unknown\")\n        .astype(\"category\")\n        .cat.codes\n        + 1\n    )\n\n# Dataset parameters\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmax_len = 384\n\n\nclass QAPairs(Dataset):\n    def __init__(self, df, is_test=False):\n        self.df = df\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        question = f\"{row['question_title']} [SEP] {row['question_body']}\"\n        question_enc = tokenizer(\n            question,\n            padding=\"max_length\",\n            max_length=max_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        answer_enc = tokenizer(\n            row[\"answer\"],\n            padding=\"max_length\",\n            max_length=max_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n\n        item = {\n            \"q_ids\": question_enc[\"input_ids\"].squeeze(),\n            \"q_mask\": question_enc[\"attention_mask\"].squeeze(),\n            \"a_ids\": answer_enc[\"input_ids\"].squeeze(),\n            \"a_mask\": answer_enc[\"attention_mask\"].squeeze(),\n            \"cat\": torch.tensor(row[\"category_idx\"], dtype=torch.long),\n            \"host\": torch.tensor(row[\"host_idx\"], dtype=torch.long),\n        }\n        if not self.is_test:\n            item[\"targets\"] = torch.tensor(\n                row[TARGETS].values.astype(np.float32), dtype=torch.float\n            )\n        return item\n\n\nclass DualBERT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n        self.cat_emb = nn.Embedding(100, 16)\n        self.host_emb = nn.Embedding(100, 16)\n        self.head = nn.Sequential(\n            nn.Linear(768 * 2 + 32, 512), nn.SiLU(), nn.Dropout(0.2), nn.Linear(512, 30)\n        )\n\n    def forward(self, q_ids, q_mask, a_ids, a_mask, cat, host):\n        q_out = self.bert(q_ids, q_mask).last_hidden_state[:, 0]\n        a_out = self.bert(a_ids, a_mask).last_hidden_state[:, 0]\n        cat_emb = self.cat_emb(cat)\n        host_emb = self.host_emb(host)\n        combined = torch.cat([q_out, a_out, cat_emb, host_emb], 1)\n        return torch.sigmoid(self.head(combined))\n\n\n# Data preparation\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntrain_ds = QAPairs(train)\nval_ds = QAPairs(val)\ntest_ds = QAPairs(test_df, is_test=True)\n\nbatch_size = 16\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=4)\n\n# Training setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = DualBERT().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\ncriterion = nn.MSELoss()\n\nbest_score = 0\nfor epoch in range(3):\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        inputs = {k: v.to(device) for k, v in batch.items() if k != \"targets\"}\n        preds = model(**inputs)\n        loss = criterion(preds, batch[\"targets\"].to(device))\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    all_preds, all_targets = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            inputs = {k: v.to(device) for k, v in batch.items() if k != \"targets\"}\n            preds = model(**inputs).cpu().numpy()\n            all_preds.append(preds)\n            all_targets.append(batch[\"targets\"].numpy())\n\n    val_preds = np.concatenate(all_preds)\n    val_targets = np.concatenate(all_targets)\n    spearman_scores = [\n        spearmanr(val_preds[:, i], val_targets[:, i]).correlation for i in range(30)\n    ]\n    mean_score = np.nanmean(spearman_scores)\n    print(f\"Epoch {epoch+1} Validation Score: {mean_score:.4f}\")\n    best_score = max(best_score, mean_score)\n\n# Generate submission\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs = {k: v.to(device) for k, v in batch.items()}\n        preds = model(**inputs).cpu().numpy()\n        test_preds.append(preds)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=TARGETS)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nos.makedirs(\"./submission\", exist_ok=True)\nsubmission.to_csv(\"./submission/submission.csv\", index=False)\nprint(f\"Final Validation Score: {best_score:.4f}\")\n",
            "analysis": "The training script successfully executed and produced a submission.csv file in the ./submission/ directory. The model achieved a validation score of 0.3536 using the mean column-wise Spearman's correlation coefficient, which is the metric to be maximized for this competition. The empirical findings indicate that the model improves in performance over the epochs, suggesting effective learning and adaptation to the task.",
            "is_bug": "False",
            "parent_index": 15,
            "node_level_analysis": "数据划分: hold-out train_test_split test_size=0.2, random_state=42\n特征工程: 数值特征标准化(StandardScaler)对10个数值特征\n类别编码: one-hot→索引 via idxmax，Wilderness_Area1-4→0-3，Soil_Type1-40→0-39\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: TensorDataset → DataLoader batch=4096, shuffle=True, num_workers=4\n模型构建: EmbeddingResNet — Embedding + MLP input(10+4+16→512)、Residual blocks (512→512, 512→512, 512→256, 256→256) 含 SE、GELU，输出 Linear 256→7\n正则化: BatchNorm1d、Dropout(p=0.3/0.2)、weight_decay=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW lr=0.001, wd=0.01；OneCycleLR max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3\n模型训练: 前向→损失→反向→更新→调度，epoch=25，保存最优模型(best_model.pt)",
            "insights_from_parent": [
                "数据预处理：数据列处理不变，仍确保targets为float",
                "特征工程：文本分词与类别索引保持一致，未扩展新特征",
                "模型选择：仍采用DualBERT，模型结构未改动",
                "参数调整：未调整学习率或架构超参数",
                "训练策略：修正Dataset输出键以匹配模型forward（q_ids,q_mask等），解决接口错配"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 20,
            "metric": 0.3246,
            "plan": "To improve the model's performance, the following enhancements are proposed:\n1. **Upgrade the base model** from BERT to RoBERTa-base for better contextual\nunderstanding, leveraging its improved architecture and training methodology.\n2. **Optimize the learning schedule** by introducing a linear learning rate\nwarmup and decay to stabilize training and enhance convergence.  3. **Extend\ntraining duration** from 3 to 5 epochs with early checkpointing to capture more\npatterns while preventing overfitting through model selection based on\nvalidation performance.",
            "code": "import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport os\n\n# Load data and define targets\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntest_df = pd.read_csv(\"./input/test.csv\")\nTARGETS = train_df.columns[-30:].tolist()\ntrain_df[TARGETS] = train_df[TARGETS].astype(float)\n\n# Preprocess categorical features\nfor col in [\"category\", \"host\"]:\n    train_values = train_df[col].unique()\n    train_df[f\"{col}_idx\"] = train_df[col].astype(\"category\").cat.codes + 1\n    test_df[f\"{col}_idx\"] = (\n        test_df[col]\n        .apply(lambda x: x if x in train_values else \"unknown\")\n        .astype(\"category\")\n        .cat.codes\n        + 1\n    )\n\n# Dataset parameters\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\nmax_len = 384\n\n\nclass QAPairs(Dataset):\n    def __init__(self, df, is_test=False):\n        self.df = df\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        # Improved text handling with separate segments\n        question_enc = tokenizer(\n            text=row[\"question_title\"],\n            text_pair=row[\"question_body\"],\n            padding=\"max_length\",\n            max_length=max_len,\n            truncation=\"only_second\",\n            return_tensors=\"pt\",\n        )\n        answer_enc = tokenizer(\n            row[\"answer\"],\n            padding=\"max_length\",\n            max_length=max_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n\n        item = {\n            \"q_ids\": question_enc[\"input_ids\"].squeeze(),\n            \"q_mask\": question_enc[\"attention_mask\"].squeeze(),\n            \"a_ids\": answer_enc[\"input_ids\"].squeeze(),\n            \"a_mask\": answer_enc[\"attention_mask\"].squeeze(),\n            \"cat\": torch.tensor(row[\"category_idx\"], dtype=torch.long),\n            \"host\": torch.tensor(row[\"host_idx\"], dtype=torch.long),\n        }\n        if not self.is_test:\n            item[\"targets\"] = torch.tensor(\n                row[TARGETS].values.astype(np.float32), dtype=torch.float\n            )\n        return item\n\n\nclass DualRoberta(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.roberta = AutoModel.from_pretrained(\"roberta-base\")\n        self.cat_emb = nn.Embedding(100, 16)\n        self.host_emb = nn.Embedding(100, 16)\n        self.head = nn.Sequential(\n            nn.Linear(768 * 2 + 32, 1024),\n            nn.GELU(),\n            nn.Dropout(0.3),\n            nn.Linear(1024, 512),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, q_ids, q_mask, a_ids, a_mask, cat, host):\n        q_out = self.roberta(q_ids, attention_mask=q_mask).last_hidden_state[:, 0]\n        a_out = self.roberta(a_ids, attention_mask=a_mask).last_hidden_state[:, 0]\n        cat_emb = self.cat_emb(cat)\n        host_emb = self.host_emb(host)\n        combined = torch.cat([q_out, a_out, cat_emb, host_emb], 1)\n        return torch.sigmoid(self.head(combined))\n\n\n# Data preparation\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntrain_ds = QAPairs(train)\nval_ds = QAPairs(val)\ntest_ds = QAPairs(test_df, is_test=True)\n\nbatch_size = 16\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=4)\n\n# Training setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = DualRoberta().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1.5e-5)\nnum_epochs = 5\nnum_training_steps = num_epochs * len(train_loader)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=int(0.1 * num_training_steps),\n    num_training_steps=num_training_steps,\n)\ncriterion = nn.MSELoss()\n\nbest_score = 0\nfor epoch in range(num_epochs):\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        inputs = {k: v.to(device) for k, v in batch.items() if k != \"targets\"}\n        preds = model(**inputs)\n        loss = criterion(preds, batch[\"targets\"].to(device))\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n    model.eval()\n    all_preds, all_targets = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            inputs = {k: v.to(device) for k, v in batch.items() if k != \"targets\"}\n            preds = model(**inputs).cpu().numpy()\n            all_preds.append(preds)\n            all_targets.append(batch[\"targets\"].numpy())\n\n    val_preds = np.concatenate(all_preds)\n    val_targets = np.concatenate(all_targets)\n    spearman_scores = [\n        spearmanr(val_preds[:, i], val_targets[:, i]).correlation for i in range(30)\n    ]\n    mean_score = np.nanmean(spearman_scores)\n    print(f\"Epoch {epoch+1} Validation Score: {mean_score:.4f}\")\n    if mean_score > best_score:\n        best_score = mean_score\n        torch.save(model.state_dict(), \"./working/best_model.pth\")\n\n# Generate final submission\nmodel.load_state_dict(torch.load(\"./working/best_model.pth\"))\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs = {k: v.to(device) for k, v in batch.items()}\n        preds = model(**inputs).cpu().numpy()\n        test_preds.append(preds)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=TARGETS)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nos.makedirs(\"./submission\", exist_ok=True)\nsubmission.to_csv(\"./submission/submission.csv\", index=False)\nprint(f\"Final Validation Score: {best_score:.4f}\")\n",
            "analysis": "The code successfully trains a DualRoberta model to predict subjective aspects of question-answer pairs, achieving a validation score of 0.3246 based on Spearman's rank correlation coefficient. The model's predictions are saved in the required 'submission.csv' file. The validation score indicates moderate correlation, suggesting room for improvement in model performance.",
            "is_bug": "False",
            "parent_index": 19,
            "node_level_analysis": "数据划分: hold-out 80/20, random_state=42\n特征工程: 数值标准化(StandardScaler)对10个数值特征\n类别编码: 从one-hot取索引生成类别索引(Wilderness, Soil)\n类别嵌入: Wilderness(4→4维)、Soil(40→16维)\n数据管道: 张量化, DataLoader(batch=4096, shuffle=True, num_workers=4)\n模型构建: Embedding + ResNet-MLP(输入10+4+16→512, blocks: 512→512 Dropout(p=0.3)×2, 512→256 Dropout(p=0.2), 256→256 Dropout(p=0.2)), ResidualBlock含SE, 输出Linear 256→7\n正则化: BatchNorm、Dropout(p=0.3/0.2)、权重衰减 wd=0.01\n损失函数: CrossEntropyLoss\n优化与调度: AdamW(lr=0.001, wd=0.01)、OneCycleLR(max_lr=0.01, total_steps=25*len(train_loader), pct_start=0.3)\n模型训练: 前向→损失→反向→更新→调度, epoch=25",
            "insights_from_parent": [
                "数据预处理：切换到RoBERTa tokenizer（roberta-base），保持文本处理流程",
                "特征工程：更规范地使用text与text_pair分段编码以改善上下文表示",
                "模型选择：从BERT换到RoBERTa-base，调整head为更深MLP并增大中间维度",
                "参数调整：降低学习率到1.5e-5，训练轮次增至5，加入线性warmup/decay调度器",
                "训练策略：引入学习率调度、梯度裁剪与基于验证集的checkpoint保存以稳定训练"
            ]
        },
        {
            "demo_id": "google-quest-challenge",
            "node_index": 23,
            "metric": null,
            "plan": "To improve the model's ability to capture interactions between questions and\nanswers, we'll switch from processing them separately to using a single RoBERTa\nmodel that processes concatenated question and answer text. This allows cross-\nattention between all tokens, potentially improving context understanding.\nAdditionally, we increase the max sequence length to 512 to retain more text and\nadjust the model architecture to leverage these changes.",
            "code": "import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import spearmanr\nimport os\n\n# Load data and define targets\ntrain_df = pd.read_csv(\"./input/train.csv\")\ntest_df = pd.read_csv(\"./input/test.csv\")\nTARGETS = train_df.columns[-30:].tolist()\ntrain_df[TARGETS] = train_df[TARGETS].astype(float)\n\n# Preprocess categorical features\nfor col in [\"category\", \"host\"]:\n    train_values = train_df[col].unique()\n    train_df[f\"{col}_idx\"] = train_df[col].astype(\"category\").cat.codes + 1\n    test_df[f\"{col}_idx\"] = (\n        test_df[col]\n        .apply(lambda x: x if x in train_values else \"unknown\")\n        .astype(\"category\")\n        .cat.codes\n        + 1\n    )\n\n# Dataset parameters\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\nmax_len = 512  # Increased sequence length\n\n\nclass QAPairs(Dataset):\n    def __init__(self, df, is_test=False):\n        self.df = df\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        # Combine question title + body and answer as two segments\n        question_part = f\"{row['question_title']} {row['question_body']}\"\n        answer_part = row[\"answer\"]\n\n        encodings = tokenizer(\n            text=question_part,\n            text_pair=answer_part,\n            padding=\"max_length\",\n            max_length=max_len,\n            truncation=\"only_second\",\n            return_tensors=\"pt\",\n        )\n\n        item = {\n            \"input_ids\": encodings[\"input_ids\"].squeeze(),\n            \"attention_mask\": encodings[\"attention_mask\"].squeeze(),\n            \"cat\": torch.tensor(row[\"category_idx\"], dtype=torch.long),\n            \"host\": torch.tensor(row[\"host_idx\"], dtype=torch.long),\n        }\n        if not self.is_test:\n            item[\"targets\"] = torch.tensor(\n                row[TARGETS].values.astype(np.float32), dtype=torch.float\n            )\n        return item\n\n\nclass CrossAttentionModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.roberta = AutoModel.from_pretrained(\"roberta-base\")\n        self.cat_emb = nn.Embedding(100, 32)\n        self.host_emb = nn.Embedding(100, 32)\n        self.head = nn.Sequential(\n            nn.Linear(768 + 64, 1024),  # CLS + categorical embeddings\n            nn.GELU(),\n            nn.Dropout(0.4),\n            nn.Linear(1024, 512),\n            nn.GELU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 30),\n        )\n\n    def forward(self, input_ids, attention_mask, cat, host):\n        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n        cls_embedding = outputs.last_hidden_state[:, 0]\n        cat_emb = self.cat_emb(cat)\n        host_emb = self.host_emb(host)\n        combined = torch.cat([cls_embedding, cat_emb, host_emb], dim=1)\n        return torch.sigmoid(self.head(combined))\n\n\n# Data preparation\ntrain, val = train_test_split(train_df, test_size=0.2, random_state=42)\ntrain_ds = QAPairs(train)\nval_ds = QAPairs(val)\ntest_ds = QAPairs(test_df, is_test=True)\n\nbatch_size = 8  # Reduced for longer sequences\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=4)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=4)\n\n# Training setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CrossAttentionModel().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1.2e-5, weight_decay=0.01)\nnum_epochs = 6\nnum_training_steps = num_epochs * len(train_loader)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=int(0.1 * num_training_steps),\n    num_training_steps=num_training_steps,\n)\ncriterion = nn.MSELoss()\n\nbest_score = 0\nfor epoch in range(num_epochs):\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        inputs = {k: v.to(device) for k, v in batch.items() if k != \"targets\"}\n        preds = model(**inputs)\n        loss = criterion(preds, batch[\"targets\"].to(device))\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n    model.eval()\n    all_preds, all_targets = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            inputs = {k: v.to(device) for k, v in batch.items() if k != \"targets\"}\n            preds = model(**inputs).cpu().numpy()\n            all_preds.append(preds)\n            all_targets.append(batch[\"targets\"].numpy())\n\n    val_preds = np.concatenate(all_preds)\n    val_targets = np.concatenate(all_targets)\n    spearman_scores = [\n        spearmanr(val_preds[:, i], val_targets[:, i]).correlation for i in range(30)\n    ]\n    mean_score = np.nanmean(spearman_scores)\n    print(f\"Epoch {epoch+1} Validation Score: {mean_score:.4f}\")\n    if mean_score > best_score:\n        best_score = mean_score\n        torch.save(model.state_dict(), \"./working/best_model.pth\")\n\n# Generate final submission\nmodel.load_state_dict(torch.load(\"./working/best_model.pth\"))\nmodel.eval()\ntest_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs = {k: v.to(device) for k, v in batch.items()}\n        preds = model(**inputs).cpu().numpy()\n        test_preds.append(preds)\n\nsubmission = pd.DataFrame(np.concatenate(test_preds), columns=TARGETS)\nsubmission.insert(0, \"qa_id\", test_df[\"qa_id\"].values)\nos.makedirs(\"./submission\", exist_ok=True)\nsubmission.to_csv(\"./submission/submission.csv\", index=False)\nprint(f\"Final Validation Score: {best_score:.4f}\")\n",
            "analysis": "The code execution failed due to a truncation error in the tokenizer. The error message indicates that the sequence to truncate was too short to respect the provided max_length. As a result, no submission.csv file was produced.",
            "is_bug": "True",
            "parent_index": 20,
            "node_level_analysis": "数据清洗: 目标列转为 float    \n数据划分: hold-out 80/20，random_state=42    \n类别编码: Ordinal 编码 category、host → 索引（test 未见值标为 \"unknown\"）    \n类别嵌入: category(100→32维)、host(100→32维)    \n特征工程: 文本拼接 question_title+question_body、answer 作为 text_pair，分词 AutoTokenizer('roberta-base')，padding=max_length，truncation=only_second，max_length=512    \n数据管道: 张量化 + DataLoader，batch=8，shuffle(train)，num_workers=4    \n模型构建: RoBERTa-base(AutoModel) 提取 CLS(768-d) 与类别嵌入拼接 → MLP head (768+64→1024→512→30) ，GELU 激活，输出 Sigmoid    \n正则化: Dropout(p=0.4)、Dropout(p=0.3)、权重衰减 wd=0.01、梯度裁剪 clip_grad_norm_(1.0)    \n损失函数: MSELoss    \n优化与调度: AdamW lr=1.2e-5, wd=0.01；线性调度带 warmup (warmup 步数=0.1*总训练步数)    \n模型训练: 前向→损失→反向→更新→调度",
            "insights_from_parent": [
                "数据预处理：将question与answer拼接为两段输入，max_len提升到512以保留更多文本",
                "特征工程：从双流编码改为单流拼接以实现跨问答token交互，类别嵌入维度增大（32）",
                "模型选择：采用单个RoBERTa处理拼接文本（可实现cross-attention），并修改MLP head结构",
                "参数调整：学习率微调为1.2e-5，batch_size降为8，训练轮次增至6，加入weight_decay=0.01",
                "训练策略：保持warmup调度与梯度裁剪，增加dropout和更严格的正则化并基于验证集选模型"
            ]
        }
    ]
]